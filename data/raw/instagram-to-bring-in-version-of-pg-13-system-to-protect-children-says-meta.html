<h1>Instagram to bring in version of PG-13 system to protect children, says Meta</h1>
<div><strong>Date :</strong> 2025-10-14T10:00:38Z &nbsp; | &nbsp; <strong>Auteur :</strong> Robert Booth UK technology editor &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>Instagram is to adopt a version of the PG-13 cinema rating system to give parents stronger controls over their teenagers’ use of the social media platform.</p> <p>Instagram, which is run by Meta, will start applying rules similar to the US “parental guidance” movie rating – first introduced 41 years ago – to all material on Instagram’s teen accounts. It means users aged under 18 will automatically be placed into the 13+ setting. They will be able to opt out only with their parents’ permission.</p> <p>While the teen accounts already hide or prohibit the recommendation of sexually suggestive content, graphic or disturbing images, and adult content such as tobacco or alcohol, the new PG-13 version will tighten restrictions further.</p> <p>Meta said it would hide or not recommend posts with strong language, certain risky stunts, and content that might encourage “harmful” behaviours, such as posts showing marijuana paraphernalia. It will also block search terms, such as “alcohol” or “gore”, even if they are misspelled.</p> <p>“While of course there are differences between movies and social media, we made these changes so teens’ experience in the 13+ setting feels closer to the Instagram equivalent of watching a PG-13 movie,” Meta said, adding that it wanted to alight its policies “with an independent standard that parents are familiar with”.</p> <p>The closest UK cinema rating to PG-13 is 12A. In the same way as PG-13/12A films such as Titanic include fleeting, but not directly sexual, nudity, the new Instagram rating will not completely prohibit nudity. Neither will it block moderate violence of the kind in The Fast and the Furious, also PG-13 in the US and designated 12A in the UK.</p> <p>The move comes after <a href="https://www.theguardian.com/technology/2025/sep/25/instagram-risk-children-safety-tools-meta">independent research</a> involving a former Meta whistleblower claimed that two-thirds (64%) of new safety tools on Instagram were ineffective. The review was led by Arturo Béjar, a former senior engineer at Meta, as well as New York University and Northeastern University academics and the UK’s Molly Rose Foundation, among others. Béjar concluded: “Kids are not safe on Instagram.” Meta rejected the report’s findings and said parents had robust tools at their fingertips.</p> <p>The UK communications regulator, Ofcom, has also demanded social media companies take “a safety-first approach” and said sites that don’t comply should expect to face enforcement action.</p> <p>The Instagram updates would start in the US, UK, Australia, and Canada and will come to Europe and the rest of the world early next year, Meta said.</p> <p>Campaigners voiced doubt the changes would guarantee safety improvements.</p> <p>Rowan Ferguson, policy manager at the Molly Rose Foundation, said: “Time and again Meta’s PR announcements do not result in meaningful safety updates for teens and as our recent report revealed they still have work to do to protect them from the most harmful content.</p> <p>“These further updates must be judged on their effectiveness and that requires transparency from Meta to allow independent testing of their safety features.”</p>