<h1>There’s no simple solution to universities’ AI worries</h1>
<div><strong>Date :</strong> 2025-06-23T16:04:05Z &nbsp; | &nbsp; <strong>Auteur :</strong> Auteur inconnu &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>I enjoyed the letter from Dr Craig Reeves (<a href="https://www.theguardian.com/technology/2025/jun/17/universities-face-a-reckoning-on-chatgpt-cheats">17 June</a>) in which he argues that higher education institutions are consciously choosing not to address <a href="https://www.theguardian.com/education/2025/jun/15/thousands-of-uk-university-students-caught-cheating-using-ai-artificial-intelligence-survey">widespread cheating using generative AI</a> so as not to sacrifice revenues from international students. He is right that international students are propping up the UK’s universities, of which <a href="https://www.theguardian.com/education/article/2024/may/16/universities-in-england-risk-closure-with-40-per-cent-facing-budget-deficits-report-office-for-students">more than two-fifths</a> will be in deficit by the end of this academic year. But it is untrue that universities could simply spot AI cheating if they wanted to. Dr Reeves says that they should use AI detectors, but the studies that he quotes rebut this&nbsp;argument. </p> <p>The last study he cites (<a href="https://arxiv.org/pdf/2403.19148">Perkins et al, 2024</a>) shows that AI detectors were accurate in fewer than 40% of cases, and that this fell to just 22% of “adversarial” cases – when the use of AI was deliberately obscured. In other words, AI detectors failed to spot that AI had been used three‑quarters of the time.</p> <p>That is why it is wrong to say there is a simple solution to the generative AI problem. Some universities are pursuing academic misconduct cases with verve against students who use AI. But because AI leaves no trace, it is almost impossible to definitively show that a student used AI, unless they admit it.</p> <p>In the meantime, institutions are switching to “secure” assessments, such as the in-person exams he celebrates. Others are designing assessments assuming students will use AI. No one is saying universities have got everything right. But we shouldn’t assume conspiracy when confusion is the&nbsp;simpler explanation.<br><strong>Josh Freeman</strong><br><em>Policy manager, Higher Education Policy Institute; author, </em><a href="https://www.hepi.ac.uk/2025/02/26/student-generative-ai-survey-2025/"><em>Student Generative AI Survey 2025</em></a></p> <p>• The use of AI to “write” things in higher education has prompted significant research and discussion in institutions, and the accurate reporting of that research is obviously important. Craig Reeves mentions three papers in support of the <a href="https://www.theguardian.com/technology/2024/dec/15/i-received-a-first-but-it-felt-tainted-and-undeserved-inside-the-university-ai-cheating-crisis">Turnitin AI checker</a>, claiming that universities opted out of this function without testing it because of fears over false positive flagging of human-written texts as AI generated. One of those papers says: “The researchers conclude that the available detection tools are neither accurate nor reliable and have a main bias towards classifying the output as human-written rather than detecting AI-generated text” (Weber-Wulff et al); and a second found Turnitin to be the second worst of the seven AI detectors tested for flagging AI generated texts, with 84% undetected (Perkins et al). An AI detector can easily avoid false positives by not flagging any texts.</p> <p>We need to think carefully about how we are going to assess work, when at a click almost limitless superficially plausible text can be produced.<br><strong>Prof Paul Johnson</strong><br><em>University of Chester</em></p> <p>• In an otherwise well thought out critique of the apparent (and possibly convenient) blind spot higher education has for the use of AI, Craig Reeves appears to be encouraging a return to traditional examinations as a means of rooting out the issue.</p> <p>While I sympathise (and believe strongly that something should be done), I hope that this return to older practices will not happen in a “one size fits all” manner. I have marked examinations for well over 30 years. During that period I have regularly been impressed by students’ understanding of a topic; I can remember only enjoying reading one examination essay. The others, no matter how good, read like paranoid streams of consciousness. A central transferable skill that degrees in the humanities offer is the ability to write well and cogently about any given topic after research. Examinations don’t – can’t – offer that.</p> <p>I would call for a move towards more analytical assessment, where students are faced with new material that must be considered in a brief period. I think that the move away from traditional essays as the sole form of assessment might help to lessen (not, of course, halt) the impact of external input. From experience, this focus also helps students move towards application of new understanding, rather than a passive digestion of ideas.<br><strong>Prof Robert McColl Millar</strong><br><em>Chair in linguistics and Scottish language, University of Aberdeen</em></p> <p><strong><em>• Have an opinion on anything you’ve read in the Guardian today? Please </em></strong><a href="mailto:guardian.letters@theguardian.com?body=Please%20include%20your%20name,%20full%20postal%20address%20and%20phone%20number%20with%20your%20letter%20below.%20Letters%20are%20usually%20published%20with%20the%20author%27s%20name%20and%20city/town/village.%20The%20rest%20of%20the%20information%20is%20for%20verification%20only%20and%20to%20contact%20you%20where%20necessary."><strong><em>email</em></strong></a><strong><em> us your letter and it will be considered for publication in our </em></strong><a href="https://www.theguardian.com/tone/letters"><strong><em>letters</em></strong></a><strong><em> section.</em></strong></p>