<h1>The big idea: why we should embrace AI doctors</h1>
<div><strong>Date :</strong> 2025-08-31T11:00:29Z &nbsp; | &nbsp; <strong>Auteur :</strong> Charlotte Blease &nbsp; | &nbsp; <strong>Journal :</strong> Books</div>
<p>We expect our doctors to be demi-gods – flawless, tireless, always right. But they are only human. Increasingly, they are stretched thin, working long hours, under immense pressure, and often with limited resources. Of course, better conditions would help, including more staff and improved systems. But even in the best-funded clinics with the most committed professionals, standards can still fall short; doctors, like the rest of us, are working with stone age minds. Despite years of training, human brains are not optimally equipped for the pace, pressure, and complexity of modern healthcare.</p> <p>Given that patient care is medicine’s core purpose, the question is who, or what, is best placed to deliver it? AI may still spark suspicion, but research increasingly shows how it could help fix some of the most persistent problems and overlooked failures – from misdiagnosis and error to unequal access to care.</p> <p>As patients, each of us will face at least one diagnostic error in our lifetimes. In England, conservative estimates suggest that about <a href="https://qualitysafety.bmj.com/content/30/12/977.long">5%</a> of primary care visits result in a failure to properly diagnose, putting millions of patients in danger. In the US, diagnostic errors cause death or permanent injury to almost <a href="https://qualitysafety.bmj.com/content/33/2/109">800,000 people</a> annually. Misdiagnosis is a greater risk if you’re among the one in 10 people worldwide with a rare disease.</p> <p>Modern medicine prides itself on being scientific, yet doctors don’t always practise what the evidence recommends. Studies show that evidence-based treatments are offered only about <a href="https://www.nejm.org/doi/full/10.1056/NEJMsa022615">half the time</a> to adults in the US. Doctors can also disagree about diagnoses. In <a href="https://www.jacr.org/article/S1546-1440(18)30714-2/abstract">a study</a> of more than 12,000 radiology images, reviewers offering second opinions disagreed with the original assessment in about one in three cases – leading to a change in treatment nearly 20% of the time. As the work day wears on, quality slips further: inappropriate antibiotic prescriptions rise, while cancer screening rates fall.</p> <p>As alarming as this is, there are understandable reasons for these failures – and viewed from another angle, it’s remarkable that doctors get it right as often as they do. The realities of being human – distraction, multitasking, even our body clocks – take a toll. But burnout, depression and cognitive ageing don’t just wear doctors down; they raise the risk of clinical mistakes.</p> <p>Medical knowledge also moves faster than doctors can keep up. By graduation, half of what medical students learn is already outdated. It takes an <a href="https://journals.sagepub.com/doi/10.1258/jrsm.2011.110180">average of</a> 17 years for research to reach clinical practice, and with a new biomedical article published every 39 seconds, even skimming the abstracts would take about 22 hours a day. There are more than 7,000 rare diseases, with 250 more identified each year.</p> <p>In contrast, AI devours medical data at lightning speed, 24/7, with no sleep and no bathroom breaks. Where doctors vary in unwanted ways, AI is consistent. And while these tools make errors too, it would be churlish to deny how impressive the latest models are, with some studies showing they <a href="https://arxiv.org/abs/2412.10849">vastly outperform human doctors</a> in clinical reasoning, including for complex medical conditions.</p> <p>AI’s superpower is spotting patterns humans miss, and these tools are surprisingly good at recognising rare diseases – often better than doctors. For example, in <a href="https://www.medrxiv.org/content/10.1101/2023.04.20.23288859v2">one 2023 study</a> researchers fed 50 clinical cases – including 10 rare conditions – into ChatGPT-4. It was asked to provide diagnoses in the form of ranked suggestions. It solved all of the common cases by the second suggestion, and got 90% of the rare conditions by the eighth – outperforming the human doctors used as comparators. Patients and their families are increasingly recognising these benefits. One child, Alex, saw 17 doctors over <a href="https://www.today.com/health/mom-chatgpt-diagnosis-pain-rcna101843">three years for chronic pain</a> – none could explain his symptoms. Desperate, his mother turned to ChatGPT, which suggested a rare condition called tethered cord syndrome. Doctors confirmed the diagnosis, and Alex is now receiving proper treatment.</p> <p>Then there’s the problem of access. Healthcare is upside down. Those most in need – the sickest, poorest, and most marginalised in society – are the ones most likely to be left behind. Packed schedules and poor public transport mean millions miss appointments. Parents and part-time workers, including those with gig economy jobs, often struggle to attend checkups. <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2451279">American Time Use Survey</a> data shows patients sacrifice two hours for a 20-minute doctor’s visit. The problems are often worse for people with disabilities, who are about <a href="https://bmjopen.bmj.com/content/7/8/e016614">four times</a> more likely to miss out on care in the UK due to issues with transport, costs and long waiting lists. Compared with men with no disability, disabled women are more than seven times more likely to have unmet needs due to the cost of care or medication.</p> <p>And yet we rarely question the idea of waiting in line at the doctor’s office in town because it’s simply the way things have always been done. AI could change that. Imagine a doctor in your pocket offering information when and where you need it. Under Labour’s 10-year plan, Wes Streeting, the health secretary, <a href="https://www.theguardian.com/politics/2025/jul/03/labour-nhs-app-hospital-league-tables-10-year-health-plan-wes-streeting">has announced</a> that patients will soon be able to discuss their health concerns with AI via the <a href="https://www.theguardian.com/society/nhs">NHS</a> app. It’s a bold step – and one that could bring quicker, actionable clinical advice for millions.</p> <p>This will only work for those who can use it, of course. Internet access is improving globally, but there are still serious gaps: 2.5 billion people remain offline. In the UK, <a href="https://www.goodthingsfoundation.org/discover/digital-inclusion-insights/digital-inclusion-insights-2024/how-deep-is-the-uks-digital-divide">8.5 million people</a> lack basic digital skills, and 3.7 million families fall below the “minimum digital living standard”, meaning they have poor connectivity, outdated devices and limited support. Confidence is a barrier too: 21% of people in the UK say they feel left behind by technology.</p> <p>At the moment, AI healthcare research almost exclusively fixates on its flaws. Examining the technology’s potential for bias and errors is a crucially important task. But this orientation doesn’t take account of the creaking and sometimes unsafe systems we already rely on. Any fair assessment of AI must be weighed against the realities of what we’ve currently got – a system that too often can be frustrating, out of reach, or just plain wrong.</p> <p>• <em>Charlotte Blease is a health researcher and the author of </em><em>Dr Bot: Why Doctors Can Fail Us – and How AI Could Save Lives</em><em>, published by Yale</em><em> </em><em>on 9 September</em><em>.</em></p> <h2><strong>Further reading</strong></h2> <p><a href="https://www.guardianbookshop.com/deep-medicine-9781541644632?utm_source=editoriallink&amp;utm_medium=merch&amp;utm_campaign=article">Deep Medicine: How Artificial Intelligence Can Make Healthcare Human Again</a> by Eric Topol (Basic Books, £28)</p> <p><a href="https://www.guardianbookshop.com/co-intelligence-9780753560778/?utm_source=editoriallink&amp;utm_medium=merch&amp;utm_campaign=article">Co-Intelligence: Living and Working with AI</a> by Ethan Mollick (WH Allen, £16.99)</p> <p><a href="https://www.guardianbookshop.com/artificial-intelligence-9780241404836/?utm_source=editoriallink&amp;utm_medium=merch&amp;utm_campaign=article">Artificial Intelligence: A Guide for Thinking Humans</a> by Melanie Mitchell (Pelican, £10.99)</p>