<h1>Online suicide forum investigated under new UK digital safety laws</h1>
<div><strong>Date :</strong> 2025-04-09T07:35:59Z &nbsp; | &nbsp; <strong>Auteur :</strong> Dan Milmo Global technology editor &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>The UK communications regulator has announced its first investigation under the new digital safety laws with an inquiry into an online suicide forum.</p> <p>Ofcom is investigating whether the site breached the Online Safety Act by failing to put in place adequate measures to shield its users from illegal content.</p> <p>The law <a href="https://www.theguardian.com/media/2025/mar/17/social-media-companies-fines-uk-illegal-content-online-safety-act">requires tech platforms to tackle illegal material</a> – such as encouraging suicide – or face the threat of fines of up to £18m or 10% of global revenue. In extreme cases, Ofcom also has the power to block access to a site or app in the UK.</p> <p>Ofcom, which is not naming the forum under investigation, said it was focusing on whether the site had put appropriate measures in place to protect UK users, whether it had failed to complete an assessment of the harms the site could cause, as required under the legislation, and whether it had responded adequately to a request for information.</p> <p>“This is the first investigation opened into an individual online service provider under these new laws,” said Ofcom.</p> <p>The <a href="https://www.bbc.co.uk/news/uk-67082224">BBC reported in 2023</a> that the forum, easily accessible to anyone on the open web, had been connected to at least 50 deaths in the UK and had tens of thousands of members with discussions including methods of suicide.</p> <p>Last month, obligations came into force under the act requiring the 100,000 services under its scope – from small sites to big platforms such as X, Facebook and Google – to implement safeguards that take action against illegal harms. The legislation lists 130 “priority offences”, or illegal content, that tech companies must tackle as a priority by ensuring their moderation systems are set up to deal with such material.</p> <p>“We’ve been clear … that failure to comply with the new online safety duties or adequately respond to our information requests may result in enforcement action, and that we would not hesitate to take swift action where we suspect there may be serious breaches,” said Ofcom.</p> <p>The Molly Rose Foundation, an internet safety charity, called on Ofcom to act “quickly and decisively” and<strong> </strong>shut down the site. MRF was established by the family of Molly Russell, a <a href="https://www.theguardian.com/uk-news/2022/sep/30/molly-russell-died-while-suffering-negative-effects-of-online-content-rules-coroner">British teenager who took her own life</a> after viewing online content related to suicide, depression and self-harm.</p> <p>“We welcome Ofcom taking the first steps to clamp down on this horrendous site, which exists only to help vulnerable people end their lives,” said Andy Burrows, the hief executive of MRF. “Every day it remains online more vulnerable people are at risk.”</p> <p>• In the UK and Ireland, Samaritans can be contacted on freephone 116 123, or email jo@samaritans.org or jo@samaritans.ie. In the US, you can call or text the National Suicide Prevention Lifeline on 988, chat on 988lifeline.org, or text HOME to 741741 to connect with a crisis counsellor. In Australia, the crisis support service Lifeline is 13 11 14. Other international helplines can be found at befrienders.org</p>