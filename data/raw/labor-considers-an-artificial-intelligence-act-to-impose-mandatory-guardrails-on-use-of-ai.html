<h1>Labor considers an artificial intelligence act to impose ‘mandatory guardrails’ on use of AI</h1>
<div><strong>Date :</strong> 2024-09-04T15:00:42Z &nbsp; | &nbsp; <strong>Auteur :</strong> Paul Karp Chief political correspondent &nbsp; | &nbsp; <strong>Journal :</strong> Australia news</div>
<p>The Australian government is considering <a href="https://www.theguardian.com/technology/2023/jun/14/eu-moves-closer-to-passing-one-of-worlds-first-laws-governing-ai">a European Union-style artificial intelligence act</a> to regulate minimum standards on high-risk AI across the whole economy.</p> <p>On Wednesday the industry and science minister, Ed Husic, released a discussion paper proposing 10 “mandatory guardrails” for high-risk AI including human oversight and the ability to challenge the use of AI or outcomes of automated decision-making.</p> <p>In a statement, Husic said Australians “know AI can do great things” but they also wanted to know protections are in place “if things go off the rails”.</p> <ul> <li><p><strong><a href="https://www.theguardian.com/email-newsletters?CMP=copyembed">Sign up for Guardian Australia’s breaking news email</a></strong></p></li> </ul> <p>“We need more people to use AI and to do that we need to build trust” by creating a regulatory framework, he said.</p> <p>Long the stuff of science fiction, generative artificial intelligence – which can create new content such as text, images, audio and code – has experienced a surge in uptake through “large language model” programs such as ChatGPT, <a href="https://www.theguardian.com/technology/2023/may/11/bard-ai-google-artificial-intelligence-chatbot-palm-2-launches-australia-chatgpt-competitor">Google’s chatbot Bard</a> and <a href="https://www.theguardian.com/technology/2023/feb/17/i-want-to-destroy-whatever-i-want-bings-ai-chatbot-unsettles-us-reporter">Microsoft Bing’s chat feature</a>.</p> <p>AI is already throwing up challenges to lawmakers and consumers, from <a href="https://www.accc.gov.au/media-release/trivago-to-pay-447-million-in-penalties-for-misleading-consumers-over-hotel-room-rates">misleading people on prices</a>, alleged defamation from <a href="https://www.theguardian.com/technology/2023/apr/06/australian-mayor-prepares-worlds-first-defamation-lawsuit-over-chatgpt-content">false claims served up by chat programs</a> to warnings from the <a href="https://www.theguardian.com/technology/2023/may/20/ai-tools-could-be-used-by-predators-to-automate-child-grooming-esafety-commissioner-warns#:~:text=The%20eSafety%20commissioner%2C%20Julie%20Inman%20Grant%2C%20said%20her%20agency%20has,regulation%20needed%20for%20the%20sector.">eSafety commissioner</a> that generative AI could automate child grooming by predators.</p> <p>The paper notes while AI can “improve wellbeing and quality of life” <a href="https://www.theguardian.com/technology/2023/jun/01/australian-government-considers-ban-on-high-risk-uses-of-ai-such-as-deepfakes-and-algorithmic-bias">its potential for harms</a> include creating and amplifying bias; physical or psychological injury; breach of privacy; and threatening national security through information manipulation and malicious cyber activity.</p> <p>The paper proposes to define high-risk AI to “intended and foreseeable uses” and the “unforeseeable risks” created by general-purpose AI, which “can be applied in contexts they were not originally designed for”.</p> <p>Under the 10 guardrails, organisations developing or deploying high-risk AI would need to establish risk management processes; test AI and monitor once deployed; enable human control or intervention to achieve meaningful human oversight; inform end-users of AI decisions, interactions and content; and establish processes for people affected by AI systems to challenge use or outcomes.</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/technology/article/2024/jul/18/ai-deepfakes-revenge-porn-reporting-portal-australia-laws">Portal needed for victims to report AI deepfakes, federal police union says</a> </p> </aside>  <p>Organisations should also be required to “keep and maintain records to allow third parties to assess compliance with guardrails” and undertake tests to certify their own compliance, it said.</p> <p>Once settled, the guardrails could be applied within existing regulations, through amendments to legislation in separate domains or through “a new cross-economy AI act”, as <a href="https://www.theguardian.com/technology/2023/jun/14/eu-moves-closer-to-passing-one-of-worlds-first-laws-governing-ai">the EU moved to do in June</a>.</p> <p>That option would enable the creation of an independent AI regulator, although this would “take resources and time”, the paper said.</p> <p>Husic said Australians want stronger protections on AI and businesses had also been calling for greater clarity around using AI safely.</p> <p>“From today, we’re starting to put those protections in place,” he said.</p> <p>The paper noted the government plans to “strengthen privacy protections, transparency and accountability”, a reference to <a href="https://www.theguardian.com/australia-news/2023/sep/27/australia-sue-breach-of-privacy-laws-new-reforms">the privacy law reform package</a> expected to be unveiled as early as next week.</p> <p>The attorney general’s department is also working on a “whole of government legal framework to support use of automated decision-making systems”, which was a recommendation from the robodebt royal commission.</p>