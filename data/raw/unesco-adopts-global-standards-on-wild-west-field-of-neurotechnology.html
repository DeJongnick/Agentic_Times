<h1>Unesco adopts global standards on ‘wild west’ field of neurotechnology</h1>
<div><strong>Date :</strong> 2025-11-06T16:00:00Z &nbsp; | &nbsp; <strong>Auteur :</strong> Aisha Down &nbsp; | &nbsp; <strong>Journal :</strong> World news</div>
<p>It is the latest move in a growing international effort to put guardrails around a burgeoning frontier – technologies that harness data from the brain and nervous system.</p> <p>Unesco has <a href="https://unesdoc.unesco.org/ark:/48223/pf0000394866/PDF/394866eng.pdf.multi">adopted</a> a set of global standards on the ethics of neurotechnology, a field that has been described as “a bit of a wild west”.</p> <p>“There is no control,” said Unesco’s chief of bioethics, Dafna Feinholz. “We have to inform the people about the risks, the potential benefits, the alternatives, so that people have the possibility to say ‘I accept, or I don’t accept’.”</p> <p>She said the new standards were driven by two recent developments in neurotechnology: artificial intelligence (AI), which offers vast possibilities in decoding brain data, and the proliferation of consumer-grade neurotech devices such as <a href="https://www.emotiv.com/?srsltid=AfmBOoq0WO2d4YUT5ya0tIDOdBDVsq5dxs0rfTPForRe0EfMuQ5PM5yp">earbuds</a> that claim to read brain activity and glasses that <a href="https://support.apple.com/en-gb/120052#:~:text=comprehensive%20glasses%20prescription.-,If%20you%20have%20a%20diagnosed%20vision%20condition,best%20to%20try%20these%20first.">track</a> eye movements.</p> <p>The standards define a new category of data, “neural data”, and suggest guidelines governing its protection. A <a href="https://unesdoc.unesco.org/ark:/48223/pf0000394866/PDF/394866eng.pdf.multi">list</a> of more than 100 recommendations ranges from rights-based concerns to addressing scenarios that are – at least for now – science fiction, such as companies using neurotechnology to subliminally market to people during their dreams.</p> <p>“Neurotechnology has the potential to define the next frontier of human progress, but it is not without risks,” said Unesco’s director general, Audrey Azoulay. The new standards would “enshrine the inviolability of the human mind”, she said.</p> <p>Billions of dollars have <a href="https://www.unesco.org/en/ethics-neurotech">poured</a> into neurotech ventures in the past few years, from Sam Altman’s August investment in Merge Labs, a competitor to Elon Musk’s Neuralink, to Meta’s recent unveiling of a <a href="https://www.meta.com/gb/ai-glasses/meta-ray-ban-display/?srsltid=AfmBOopXZK7Nh7QDrgsL7XGCB4MjNAmPyrSfPUHy1kRRjmejNyYuJz6Y">wristband</a> that allows users to control their phone or AI Ray-Bans by reading muscle movements in their wrist.</p> <p>The wave of investment has brought with it a growing push for regulation. The World Economic Forum released a <a href="https://www.weforum.org/stories/2025/10/beyond-neural-data-a-technology-neutral-approach-to-privacy/">paper</a> last month calling for a privacy oriented framework, and the US senator Chuck Schumer introduced the Mind Act in September – following the lead of four states that have introduced laws to protect “neural data” since 2024.</p> <p>Advocates for neurotech regulation emphasise the importance of safeguarding personal data. Unesco’s standards highlight the need for “mental privacy” and “freedom of thought”. </p> <p>Sceptics, however, say legislative efforts are often driven by dystopian anxieties and risk hampering vital medical advances.</p> <p>“What’s happening with all this legislation is fear. People are afraid of what this technology is capable of. The idea of neurotech reading people’s minds is scary,” said Kristen Mathews, a lawyer who works on mental privacy issues at the US law firm Cooley.</p> <p>From a technical perspective, neurotechnology has been around for more than 100 years. The electroencephalogram<strong> </strong>(EEG) was invented in 1924, and the first brain-computer interfaces were developed in the 1970s. The latest wave of investment, however, is driven by advances in AI that make it possible to decode large amounts of data – including, possibly, brainwaves.</p> <p>“The thing that has enabled this technology to present perceived privacy issues is the introduction of AI,” said Mathews.</p> <p>Some AI-enabled neurotech advances could be medically transformative, helping treat conditions from Parkinson’s disease to amyotrophic lateral sclerosis (ALS).</p> <p>A <a href="https://www.nature.com/articles/d41586-025-01001-6#:~:text=A%20brain%2Dreading%20implant%20that,into%20speech%20within%203%20seconds.&amp;text=The%20findings%2C%20published%20in%20Nature,of%20natural%20speech%2C%20he%20adds.">paper</a> published in Nature this summer described an AI-powered brain-computer interface decoding the speech of a paralysis patient. Other <a href="https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2">work</a> suggests AI may one day be able to “read” your thoughts – or at least, reconstruct an image if you concentrate on it hard.</p> <p>The hype around some of these advances has generated fears that Mathews said were often far removed from the real dangers. The Mind Act, for example, <a href="https://www.commerce.senate.gov/services/files/A175D9D8-6CF8-4733-B2F6-43C19FE4CB74f">says</a> AI and the “vertical corporate integration” of neurotechnology could lead to “cognitive manipulation” and “erosion of personal autonomy”.</p> <p>“I’m not aware of any company that’s doing any of this stuff. It’s not going to happen. Maybe two decades from now,” she said.</p> <p>The current frontier of neurotechnology lies in improving brain-computer interfaces, which despite recent breakthroughs are in their <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11004276/">infancy</a> – and in the proliferation of consumer-oriented devices, which Mathews said could raise privacy concerns, a bugbear of the Unesco standards. She argues, however, that creating the concept of “neural data” is too broad an approach to this issue.</p> <p>“That’s the type of thing that we would want to address. Monetising, behavioural advertising, using neural data. But the laws that are out there, they’re not getting at the stuff we’re worried about. They’re more amorphous.”</p>