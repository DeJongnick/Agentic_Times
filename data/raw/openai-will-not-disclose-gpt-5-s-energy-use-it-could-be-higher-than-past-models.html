<h1>OpenAI will not disclose GPT-5’s energy use. It could be higher than past models</h1>
<div><strong>Date :</strong> 2025-08-09T10:00:05Z &nbsp; | &nbsp; <strong>Auteur :</strong> Aisha Kehoe Down &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>In mid-2023, if a user asked OpenAI’s ChatGPT for a recipe for artichoke <a href="https://www.outsideonline.com/food/food-culture/i-spent-a-day-following-ai-recipes-and-it-was-both-delicious-and-freaky/">pasta</a> or instructions on how to make a ritual <a href="https://www.theatlantic.com/technology/archive/2025/07/chatgpt-ai-self-mutilation-satanism/683649/">offering</a> to the ancient Canaanite deity Moloch, its response might have taken – very roughly – 2 watt-<a href="https://arxiv.org/pdf/2304.03271">hours</a>, or about as much electricity as an incandescent bulb consumes in 2 minutes.</p> 
<p>OpenAI <a href="https://www.theguardian.com/technology/2025/aug/07/openai-chatgpt-upgrade-big-step-forward-human-jobs-gpt-5">released</a> a model on Thursday that will underpin the popular chatbot – <a href="https://www.theguardian.com/technology/2025/aug/07/openai-chatgpt-upgrade-big-step-forward-human-jobs-gpt-5">GPT-5</a>. Ask that version of the AI for an artichoke recipe, and the same amount of pasta-related text could take several times – even 20 times – that amount of energy, experts say.</p> 
<p>As it rolled out GPT-5, the company <a href="https://www.theguardian.com/technology/2025/aug/07/openai-chatgpt-upgrade-big-step-forward-human-jobs-gpt-5">highlighted</a> the model’s breakthrough capabilities: its ability to create websites, answer PhD-level science questions, and reason through difficult problems.</p> 
<p>But experts who have spent the past years working to benchmark the energy and resource usage of AI models say those new powers come at a cost: a response from GPT-5 may take a significantly larger amount of energy than a response from previous versions of ChatGPT.</p> 
<aside class="element element-rich-link element--thumbnail"> 
 <p> <span>Related: </span><a href="https://www.theguardian.com/australia-news/2025/aug/08/openai-chatgpt-5-struggled-with-spelling-and-geography">OpenAI unveils ChatGPT-5 and its hyped ‘PhD level’ intelligence struggled with basic spelling and geography</a> </p> 
</aside> 
<p>OpenAI, like most of its competitors, has released no official information on the power usage of its models since GPT-3, which came out in 2020. Sam Altman, its CEO, tossed out some <a href="https://blog.samaltman.com/the-gentle-singularity">numbers</a> on ChatGPT’s resource consumption on his blog this June. However, these figures, 0.34 watt-hours and 0.000085 gallons of water per query, do not refer to a specific model and have no supporting documentation.</p> 
<p>“A more complex model like GPT-5 consumes more power both during training and during inference. It’s also targeted at long thinking … I can safely say that it’s going to consume a lot more power than GPT-4,” said Rakesh Kumar, a professor at the University of Illinois, currently working on the energy consumption of computation and AI models.</p> 
<p>The day GPT-5 was released, <a href="https://arxiv.org/pdf/2505.09598v2">researchers</a> at the University of Rhode Island’s AI lab found that the model can use up to 40 watt-hours of electricity to generate a medium-length response of about 1,000 tokens, which are the building blocks of text for an AI model and are approximately equivalent to words.</p> 
<p>A <a href="https://app.powerbi.com/view?r=eyJrIjoiZjVmOTI0MmMtY2U2Mi00ZTE2LTk2MGYtY2ZjNDMzODZkMjlmIiwidCI6IjQyNmQyYThkLTljY2QtNDI1NS04OTNkLTA2ODZhMzJjMTY4ZCIsImMiOjF9">dashboard</a> they put up on Friday indicates GPT-5’s average energy consumption for a medium-length response is just over 18 watt-hours, a figure that is higher than all other models they benchmark except for OpenAI’s o3 reasoning model, released in April, and R1, made by the Chinese AI firm Deepseek.</p> 
<p>This is “significantly more energy than GPT-4o”, the previous model from OpenAI, said Nidhal Jegham, a researcher in the group.</p> 
<p>Eighteen watt-hours would correspond to burning that incandescent bulb for 18 minutes. Given recent <a href="https://www.theverge.com/news/710867/openai-chatgpt-daily-prompts-2-billion">reports</a> that ChatGPT handles 2.5bn requests a day, the total consumption of GPT-5 could reach the daily electricity <a href="https://www.eia.gov/energyexplained/use-of-energy/electricity-use-in-homes.php#:~:text=Electricity%20consumption%20in%20U.S.%20homes,kWh)%20of%20electricity%20per%20year.">demand</a> of 1.5m US homes.</p> 
<p>As large as these numbers are, researchers in the field say they align with their broad expectations for GPT-5’s energy consumption, given that GPT-5 is believed to be several times larger than OpenAI’s previous models. OpenAI has not released the parameter counts – which determine a model’s size – for any of its models since GPT-3, which <a href="https://arxiv.org/pdf/2005.14165">had 175bn</a> <a href="https://developer.nvidia.com/blog/openai-presents-gpt-3-a-175-billion-parameters-language-model/">parameters</a>.</p> 
<p>A disclosure this summer from the French AI company Mistral <a href="https://mistral.ai/news/our-contribution-to-a-global-environmental-standard-for-ai">finds</a> a “strong correlation” between a model’s size and its energy consumption, based on Mistral’s study of its in-house systems.</p> 
<p>“Based on the model size, the amount of resources [used by GPT-5] should be orders of magnitude higher than that for GPT-3,” said Shaolei Ren, a professor at the University of California, Riverside who studies the <a href="https://arxiv.org/pdf/2304.03271">resource</a> footprint of AI.</p> 
<h2><strong>Benchmarking AI power usage</strong></h2> 
<p>GPT-4 was <a href="https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/">widely</a> <a href="https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/">believed</a> to be 10 times the size of GPT-3. Jegham, Kumar, Ren and others say that GPT-5 is likely to be significantly larger than GPT-4.</p> 
<p>Leading AI companies like OpenAI <a href="https://openai.com/index/planning-for-agi-and-beyond/">believe</a> that <a href="https://www.ibm.com/think/news/agi-right-goal">extremely</a> <a href="https://blog.samaltman.com/three-observations">large</a> models may be necessary to achieve AGI, that is, an AI system <a href="https://www.theguardian.com/technology/2025/aug/07/openai-chatgpt-upgrade-big-step-forward-human-jobs-gpt-5">capable</a> of doing humans’ jobs. Altman has argued strongly for this view, <a href="https://blog.samaltman.com/three-observations">writing</a> in February: “It appears that you can spend arbitrary amounts of money and get continuous and predictable gains,” though he said GPT-5 did not surpass human intelligence.</p> 
<p>In its benchmarking <a href="https://mistral.ai/news/our-contribution-to-a-global-environmental-standard-for-ai">study</a> in July, which looked at the power consumption, water usage and carbon emissions for Mistral’s Le Chat bot, the startup found a one-to-one relationship between a model’s size and its resource consumption, writing: “A model 10 times bigger will generate impacts one order of magnitude larger than a smaller model for the same amount of generated tokens.”</p> 
<p>Jegham, Kumar and Ren said that while GPT-5’s scale is significant, there are probably other factors that will come into play in determining its resource consumption. GPT-5 is deployed on more efficient hardware than some previous models. GPT-5 <a href="https://openai.com/index/introducing-gpt-5/">appears</a> to use a “mixture-of-experts” architecture, which means that it is streamlined so that not all of its parameters are activated when responding to a query, a construction which will probably cut its energy consumption.</p> 
<p>On the other hand, GPT-5 is also a reasoning model, and works in video and images as well as text, which probably makes its energy footprint far greater than text-only operations, both Ren and Kumar say – especially as the reasoning mode means that the model will compute for a longer time before responding to a query.</p> 
<p>“If you use the reasoning mode, the amount of resources you spend for getting the same answer will likely be several times higher, five to 10,” said Ren.</p> 
<h2><strong>Hidden information</strong></h2> 
<p>In order to calculate an AI model’s resource consumption, the group at the University of Rhode Island multiplied the average time that model takes to respond to a query – be it for a pasta recipe or an offering to Moloch – by the model’s average power draw during its operation.</p> 
<p>Estimating a model’s power draw was “a lot of work”, said Abdeltawab Hendawi, a <a href="https://web.uri.edu/cs/meet/abdeltawab-hendawi/">professor</a> of data science at Providence College. The group struggled to find information on how different models are deployed within data centers. Their final <a href="https://arxiv.org/pdf/2505.09598v2">paper</a> contains estimates for which chips are used for a given model, and how different queries are parceled out between different chips in a datacenter.</p> 
<p>Altman’s June blogpost confirmed their findings. The figure he gave for ChatGPT’s energy consumption per query, 0.34 watt-hours per query, closely matches what the group found for GPT-4o.</p> 
<p>Hendawi, Jegham and others in their group said that their findings underscored the need for more transparency from AI companies as they release ever-larger models.</p> 
<p>“It’s more critical than ever to address AI’s true environmental cost,” said Marwan Abdelatti, a <a href="https://www.linkedin.com/in/mabdelatti/">professor</a> at URI. “We call on OpenAI and other developers to use this moment to commit to full transparency by publicly disclosing GPT-5’s environmental impact.”</p> 
<figure class="element element-atom"> <gu-atom data-atom-id="ea05a110-2f0f-41ea-ba0a-8d9189dbddb7" data-atom-type="guide"> 
  <div>
   <div class="atom-Guide">
    <p><strong></strong></p>
    <p></p>
    <p>The best public interest journalism relies on first-hand accounts from people in the know.</p>
    <p></p>
    <p>If you have something to share on this subject, you can contact us confidentially using the following methods.</p>
    <p></p>
    <p><strong>Secure Messaging in the Guardian app</strong></p>
    <p></p>
    <p>The Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.</p>
    <p></p>
    <p>If you don't already have the Guardian app, download it (<a href="https://apps.apple.com/app/the-guardian-live-world-news/id409128287">iOS</a>/<a href="https://play.google.com/store/apps/details?id=com.guardian">Android</a>) and go to the menu. Select ‘Secure Messaging’. </p>
    <p></p>
    <p><strong>SecureDrop, instant messengers, email, telephone and post</strong></p>
    <p></p>
    <p>If you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our <a href="https://www.theguardian.com/securedrop">SecureDrop platform</a>.</p>
    <p></p>
    <p>Finally, our guide at <a href="https://www.theguardian.com/tips">theguardian.com/tips</a>&nbsp;lists several ways to contact us securely, and discusses the pros and cons of each.&nbsp;</p>
    <p></p>
   </div>
  </div>
 </gu-atom> 
</figure>