<h1>AI race heats up as OpenAI, Google and Mistral release new models</h1>
<div><strong>Date :</strong> 2024-04-10T11:56:50Z &nbsp; | &nbsp; <strong>Auteur :</strong> Alex Hern UK technology editor &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>OpenAI, Google, and the French artificial intelligence startup Mistral have all released new versions of their frontier AI models within 12 hours of one another, as the industry prepares for a burst of activity over the summer.</p> <p>The unprecedented flurry of releases come as the sector readies for the expected launch of the next major version of GPT, the system that underpins OpenAI’s hit chatbot Chat-GPT.</p> <p>The first came only hours after Nick Clegg appeared <a href="https://www.theguardian.com/technology/2024/apr/09/metas-nick-clegg-plays-down-ais-threat-to-global-democracy">on stage at an event in London</a>, where he confirmed reports that the third version of Meta’s own AI model, Llama, would be published in a matter of weeks.</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/technology/2024/apr/09/elon-musk-predicts-superhuman-ai-will-be-smarter-than-people-next-year">Elon Musk predicts superhuman AI will be smarter than people next year</a> </p> </aside>  <p>Seven hours after Clegg left the stage, Google’s Gemini Pro 1.5, his competitor’s most advanced large language model, was released to the general public, with a free tier limited to 50 requests a day.</p> <p>An hour later, OpenAI released its own frontier model, the final version of GPT-4 Turbo. GPT-4 Turbo and Gemini Pro 1.5 are “multimodal” systems, able to accept more than just text. Each can take image input, while Gemini can also accept audio and video.</p> <p>In the early hours of the morning in France, Mistral, an AI startup founded by a number of Clegg’s former colleagues in Meta’s AI team, released its frontier model, Mixtral 8x22B. Unlike its two American competitors, Mixtral was released through a simple download link to a 281GB file: the company, like Meta, takes an “open source” approach, and publishes its AI systems free for anyone to download and build upon.</p> <p>That approach has been criticised as potentially dangerous, since it leaves the developer unable to intervene and stop its systems being used for harmful ends, nor to pull models offline if vulnerabilities or biases are discovered and need to be fixed. Others, including Meta, <a href="https://www.theguardian.com/technology/2024/jan/19/mark-zuckerberg-artificial-general-intelligence-system-alarms-experts-meta-open-source">defend it as ultimately leading to better outcomes</a> than systems “kept in the clammy hands of a small number of very, very large, well-heeled companies in California”.</p> <p>Meta’s Llama 3 is expected to be released initially in its smaller, less powerful versions, <a href="https://www.theinformation.com/articles/meta-platforms-to-launch-small-versions-of-llama-3-next-week">according to a report from The Information</a>, building up to a release of the company’s most advanced frontier model this summer. However, it may face stiff competition: OpenAI is believed to be planning a similar timeframe for its next GPT model, GPT-5, with the company’s chief operating officer, Brad Lightcap, telling the Financial Times <a href="https://www.ft.com/content/78834fd4-c4d1-4bab-bc40-a64ad9d65e0d">it would be coming “soon”</a>.</p> <p>However, experts have queried whether the “large language model” approach shared by all frontier AI systems might be hitting its limits. “We hear a lot of people saying: ‘Oh my God, we’re going to get [artificial general intelligence] within the next year,” said Meta’s chief AI scientist, Yann LeCun, responding to <a href="https://www.theguardian.com/technology/2024/apr/09/elon-musk-predicts-superhuman-ai-will-be-smarter-than-people-next-year?ref=upstract.com">a claim from the xAI founder, Elon Musk</a>. “It’s just not happening. We have AI systems that can pass the bar exam, but they can’t clear up your dinner table and fill up the dishwasher. We have systems that manipulate language, and fool us into thinking that they are smart, but cannot understand the world.”</p> <p>Instead, LeCun suggested, researchers needed to work on what he called “objective-driven” AI with the ability to reason and plan about the world, rather than just work on words alone.</p> <p>That approach might generate AI systems with truly superhuman abilities, LeCun said. That “is more of a vision than anything else”, he added, “but it’s making exponential progress, so I’m pretty confident that we’ll get there”.</p>