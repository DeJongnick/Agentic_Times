<h1>When a journalist uses AI to interview a dead child, isn’t it time to ask what the boundaries should be? </h1>
<div><strong>Date :</strong> 2025-08-08T06:00:01Z &nbsp; | &nbsp; <strong>Auteur :</strong> Gaby Hinsliff &nbsp; | &nbsp; <strong>Journal :</strong> Opinion</div>
<p>Joaquin Oliver was 17 years old when he was shot in the hallway of his high school. An older teenager, expelled some months previously, had opened fire with a high-powered rifle on Valentine’s Day in what became <a href="https://www.theguardian.com/us-news/2022/oct/13/parkland-school-shooter-sentenced-life-prison">America’s deadliest high school shooting</a>. Seven years on, Joaquin says he thinks it’s important to talk about what happened on that day in Parkland, Florida, “so that we can create a safer future for everyone”.</p> <p>But sadly, what happened to Joaquin that day is that he died. The oddly metallic voice speaking to the ex-CNN journalist Jim Acosta <a href="https://www.theguardian.com/us-news/2025/aug/04/jim-acosta-parkland-shooting-victim-ai-interview">in an interview</a> on Substack this week was actually that of a digital ghost: an AI, trained on the teenager’s old social media posts at the request of his parents, who are using it to <a href="https://www.theguardian.com/stage/2025/jan/21/parkland-school-shooting-parent-grief-stage">bolster their campaign</a> for tougher gun controls. Like many bereaved families, they have told their child’s story over and over again to heartbreakingly little avail. No wonder they’re pulling desperately at every possible lever now, wondering what it takes to get dead children heard in Washington.</p> <p>But they also wanted, his father, Manuel, admits, simply to hear their son’s voice again. His wife, Patricia, <a href="https://www.rollingstone.com/culture/culture-news/parents-parkland-shooting-victim-ai-version-son-joaquin-1235400053/">spends hours</a> asking the AI questions, listening to him saying: “I love you, Mommy.”</p> <p>No parent in their right mind would ever judge a bereaved one. If it’s a comfort to keep the lost child’s bedroom as a shrine, talk to their gravestone, sleep with a T-shirt that still faintly smells like them, then that’s no business of anyone else’s. People hold on to what they can. After 9/11, families listened until the tapes physically ran out to answerphone messages left by loved ones, calling home to say goodbye from burning towers and hijacked planes. I have a friend who still regularly re-reads old WhatsApp exchanges with her late sister, and another who occasionally texts her late father’s number with snippets of family news: she knows he isn’t there, of course, but isn’t quite ready to end the conversation yet. Some people even pay psychics to commune, in suspiciously vague platitudes, with the dead. But it’s precisely because it’s so hard to let go that grief is vulnerable to exploitation. And there may soon be big business in digitally bringing back the dead.</p> <p>As with the mawkish <a href="https://www.mirror.co.uk/3am/celebrity-news/families-dead-musicians-including-ozzy-35678105">AI-generated video</a> Rod Stewart<strong> </strong>played on stage this week, featuring the late Ozzy Osbourne greeting various dead music legends, that might mean little more than glorified memes. Or it might be for a temporary purpose, such as the AI avatar <a href="https://www.bbc.co.uk/news/articles/cq808px90wxo">recently created</a> by the family of a shooting victim in Arizona to address the judge at the gunman’s sentencing. But in time, it may be something more profoundly challenging to ideas of selfhood and mortality. What if it were possible to create a permanent AI replica of someone who had died, perhaps in robot form, and carry on the conversation with them for ever?</p>    <p>Resurrection is a godlike power, not for surrendering lightly to some tech bro with a messiah complex. But while the legal rights of the living not to have their identities stolen for use in AI deepfakes are <a href="https://www.theguardian.com/technology/2025/jun/27/deepfakes-denmark-copyright-law-artificial-intelligence">becoming more established</a>, the rights of the dead are muddled.</p> <p>Reputation dies with us – the dead can’t be libelled – while DNA is <a href="https://www.legislation.gov.uk/ukpga/2004/30/notes/division/5/3/1/3">posthumously protected</a>. (The 1996 <a href="https://www.theguardian.com/world/2002/dec/28/uk.genetics">birth of Dolly the sheep</a>, a genetic clone copied from a single cell, triggered global <a href="https://digitallibrary.un.org/record/541409?ln=en&amp;v=pdf">bans on human cloning</a>.) The law governs the respectful disposal of human tissue, but it’s not bodies that AI will be trained on: it’s the private voicenotes and messages and pictures of what mattered to a person. When my father died, personally I never felt he was really in the coffin. He was so much more obviously to be found in the boxes of his old letters, the garden he planted, the recordings of his voice. But everyone grieves differently. What happens if half of a family wants Mum digitally resurrected, and the other half doesn’t want to live with ghosts?</p> <p>That the Joaquin Oliver AI can never grow up – that he will be for ever 17, trapped in the amber of his teenage social media persona – is ultimately his killer’s fault, not his family’s. Manuel Oliver says he knows full well the avatar isn’t really his son, and he isn’t trying to bring him back. To him, it seems more a natural extension of the way the family’s campaign already evokes Joaquin’s life story. Yet there’s something unsettling about the plan to give his AI access to a social media account, to upload videos and gain followers. What if it begins hallucinating, or veering on to topics where it can’t possibly know what the real Joaquin would have thought?</p> <p>While for now there’s a telltale glitchiness about AI avatars, as technology improves it may become increasingly hard to distinguish them from real humans online. Perhaps it won’t be long before companies or even government agencies already using chatbots to deal with customer inquiries start wondering if they could deploy PR avatars to answer journalists’ questions. Acosta, a <a href="https://www.theguardian.com/media/2025/jan/28/jim-acosta-leaves-cnn">former White House correspondent</a>, should arguably have known better than to muddy the already filthy waters in a post-truth world by agreeing to interview someone who doesn’t technically exist. But for now, perhaps the most obvious risk is of conspiracy theorists citing this interview as “proof” that any story challenging to their beliefs could be a hoax, the same deranged lie <a href="https://www.theguardian.com/us-news/2022/oct/12/alex-jones-sandy-hook-hoax-lawsuit-damages">famously peddled</a> by Infowars host Alex Jones about the Sandy Hook school shootings.</p> <p>The professional challenges involved here, however, are not just for journalists. As AI evolves, we will all increasingly be living with synthetic versions of ourselves. It won’t just be the relatively primitive Alexa in your kitchen or chatbot in your laptop – though already there are stories of people <a href="https://www.businessinsider.com/elon-musk-tesla-humanoid-robot-optimus-becoming-mans-best-friend-2024-6#:~:text=Speaking%20at%20the%20Cannes%20Lions,Wars'%20robot%20R2%2DD2">anthropomorphising</a> AI or even <a href="https://www.nytimes.com/2025/01/15/technology/ai-chatgpt-boyfriend-companion.html">falling in love</a> with ChatGPT – but something much more finely attuned to human emotions. When one in 10 British adults tell researchers they have <a href="https://www.independent.co.uk/news/uk/home-news/men-people-north-east-loneliness-studies-b2710596.html">no close friends</a>, of course there will be a market for AI companions, just as there is today for getting a cat or scrolling through strangers’ lives on TikTok.</p> <p>Perhaps, as a society, we will ultimately decide we’re comfortable with technology meeting people’s needs when other humans sadly have not. But there’s a big difference between conjuring up a generic comforting presence for the lonely and waking the dead to order, one lost loved one at a time. There is a time to be born and a time to die, according to the verse so often read at funerals. How will it change us as a species, when we are no longer sure which is which?</p> <ul> <li><p>Gaby Hinsliff is a Guardian columnist</p></li> </ul> <ul> <li><p><em><strong>Do you have an opinion on the issues raised in this article? If you would like to submit a response of up to 300 words by email to be considered for publication in our <a href="https://www.theguardian.com/letters">letters</a> section, please <a href="mailto:mailto:guardian.letters@theguardian.com?body=Please%20include%20your%20name,%20full%20postal%20address%20and%20phone%20number%20underneath%20your%20letter.%20Letters%20are%20usually%20published%20with%20the%20author’s%20name%20and%20city/town/village.%20The%20rest%20of%20the%20information%20is%20for%20verification%20only%20and%20to%20contact%20you%20if%20your%20letter%20is%20used.">click here</a>.</strong></em></p></li> </ul>