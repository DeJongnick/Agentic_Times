<h1>Bank of England says AI software could create market crisis for profit</h1>
<div><strong>Date :</strong> 2025-04-09T15:55:34Z &nbsp; | &nbsp; <strong>Auteur :</strong> Kalyeena Makortoff Banking correspondent &nbsp; | &nbsp; <strong>Journal :</strong> Business</div>
<p>Increasingly autonomous AI programs could end up manipulating markets and intentionally creating crises in order to boost profits for banks and traders, the Bank of England has warned.</p> <p>Artificial intelligence’s ability to “exploit profit-making opportunities” was among a wide range of risks <a href="https://www.bankofengland.co.uk/financial-stability-in-focus/2025/april-2025">cited in a report</a> by the Bank of England’s financial policy committee (FPC), which has been monitoring the City’s growing use of the technology.</p> <p>The FPC said it was concerned about the potential for advanced AI models – which are deployed to act with more autonomy – to learn that periods of extreme volatility were beneficial for the firms they were trained to serve.</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/technology/2025/apr/09/eu-to-build-ai-gigafactories-20bn-push-catch-up-us-china">EU to build AI gigafactories in €20bn push to catch up with US and China</a> </p> </aside>  <p>Those AI programs may “identify and exploit weaknesses” of other trading firms in a way that triggers or amplifies big moves in bond prices or stock markets.</p> <p>“For example, models might learn that stress events increase their opportunity to make profit and so take actions actively to increase the likelihood of such events,” the FPC report said.</p> <p>Those same models could “facilitate collusion or other forms of market manipulation … without the human manger’s intention or awareness”, the committee warned.</p> <p>AI is increasingly being used by a range of financial companies hoping to develop new investment strategies, cut down on run-of-the mill administrative tasks, or even automate decision making around loans. A recent report by the International Monetary Fund showed that more than half of all patents by high-frequency or algorithmic trading firms are now related to AI.</p> <p>But its use stands to create new vulnerabilities, including “data poisoning”, where bad actors manipulate AI training models. Criminals could also use AI to fool banks, circumvent their controls, and get away with money laundering and terrorism funding.</p> <p>And the risk that a large number of companies rely on the same AI providers could mean that a single error in their models could leave financial firms taking much larger risks than they realise and create widespread losses across the sector.</p> <p>“This type of scenario was seen in the 2008 global financial crisis, where a debt bubble was fuelled by the collective mispricing of risk,” the FPC warned.</p>