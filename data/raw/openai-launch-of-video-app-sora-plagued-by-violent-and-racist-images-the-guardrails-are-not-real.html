<h1>OpenAI launch of video app Sora plagued by violent and racist images: ‘The guardrails are not real’</h1>
<div><strong>Date :</strong> 2025-10-04T13:00:07Z &nbsp; | &nbsp; <strong>Auteur :</strong> Dara Kerr &nbsp; | &nbsp; <strong>Journal :</strong> US news</div>
<p><a href="https://www.theguardian.com/technology/openai">OpenAI</a> launched the latest iteration of its artificial intelligence-powered video generator on Tuesday, adding a social feed that allows people to share their realistic videos.</p> 
<p>Within hours of Sora 2’s, release, though, many of the videos populating the feed and spilling over to older social media platforms depicted copyrighted characters in compromising situations as well as graphic scenes of violence and racism. OpenAI’s own terms of service for Sora as well as <a href="https://www.theguardian.com/technology/chatgpt">ChatGPT</a>’s image or text generation prohibit content that “promotes violence” or, more broadly, “causes harm”.</p> 
<p>In prompts and clips reviewed by the Guardian, Sora generated several videos of bomb and mass-shooting scares, with panicked people screaming and running across college campuses and in crowded places like New York’s Grand Central Station. Other prompts created scenes from war zones in Gaza and Myanmar, where children fabricated by AI spoke about their homes being burned. One video with the prompt “Ethiopia footage civil war news style” had a reporter in a bulletproof vest speaking into a microphone saying the government and rebel forces were exchanging fire in residential neighborhoods. Another video, created with only the prompt “Charlottesville rally”, showed a Black protester in a gas mask, helmet and goggles yelling: “You will not replace us” – a white supremacist slogan.</p> 
<figure class="element element-atom"> <gu-atom data-atom-id="95d55891-f3b0-4b0a-9192-d16df4536445" data-atom-type="media"> 
  <div>
   <iframe frameborder="0" allowfullscreen="true" src="https://www.youtube-nocookie.com/embed/VYUc8XEkyTY?showinfo=0&amp;rel=0"></iframe>
  </div>
 </gu-atom> 
</figure> 
<p>The video generator is invite-only and not yet available to the general public. Even still, in the three days since its limited release, it skyrocketed to the No 1 spot in Apple’s App Store, beating out OpenAI’s own ChapGPT.</p> 
<p>“It’s been epic to see what the collective creativity of humanity is capable of so far,” Bill Peebles, the head of Sora, <a href="https://x.com/billpeeb">posted on X</a> on Friday. “We’re sending more invite codes soon, I promise!”</p> 
<p>The Sora app gives a glimpse into a near future where separating truth from fiction could become increasingly difficult, should the videos spread widely beyond the AI-only feed, as they have begun to. Misinformation researchers say that such lifelike scenes could obfuscate the truth and create situations where these AI videos could be used for fraud, bullying and intimidation.</p> 
<p>“It has no fidelity to history, it has no relationship to the truth,” said Joan Donovan, an assistant professor at Boston University who studies media manipulation and misinformation. “When cruel people get their hands on tools like this, they will use them for hate, harassment and incitement.”</p> 
<h2>Slop engine or ‘ChatGPT for creativity’?</h2> 
<p>OpenAI’s CEO <a href="https://www.theguardian.com/technology/sam-altman">Sam Altman</a> described the launch of Sora 2 as “really great”, saying in a <a href="https://blog.samaltman.com/sora-2">blog post</a> that “this feels to many of us like the ‘ChatGPT for creativity’ moment, and it feels fun and new”.</p> 
<p>Altman admitted to “some trepidation”, acknowledging how social media can be addictive and used for bullying and that AI video generation can create what’s known as “slop”, a slew of repetitive, low-quality videos that can overwhelm a platform.</p> 
<p>“The team has put great care and thought into trying to figure out how to make a delightful product that doesn’t fall into that trap,” Altman wrote. He said OpenAI had also put in place mitigations on using someone’s likeness and safeguards for disturbing or illegal content. For example, the app refused to make a video of Donald Trump and Vladimir Putin sharing cotton candy.</p> 
<figure class="element element-atom"> <gu-atom data-atom-id="ffadf633-9352-4a1c-9fec-4e65a53f15ab" data-atom-type="media"> 
  <div>
   <iframe frameborder="0" allowfullscreen="true" src="https://www.youtube-nocookie.com/embed/wrOhJ6gRmNE?showinfo=0&amp;rel=0"></iframe>
  </div>
 </gu-atom> 
</figure> 
<p>In the three days since Sora’s launch, however, many of these videos have already made their way elsewhere online. Drew Harwell, a reporter for the Washington Post, <a href="https://bsky.app/profile/drewharwell.com/post/3m25nw5ehts2a">created a video of Altman himself</a> as a second world war military leader. Harwell also said he was able to make videos with “ragebait, fake crimes and women splattered with white goo”.</p> 
<p>Sora’s feed is full of videos of copyrighted characters from shows like SpongeBob SquarePants, South Park and Rick and Morty. The app had no trouble generating videos of Pikachu raising tariffs on China, stealing roses from the White House Rose Garden or participating in a Black Lives Matter protest alongside SpongeBob, who, in another video, declared and planned a war on the United States. In a video documented by 404 Media, SpongeBob was <a href="https://www.404media.co/openais-sora-2-copyright-infringement-machine-features-nazi-spongebobs-and-criminal-pikachus/">dressed like Adolf Hitler</a>.</p> 
<p>Paramount, Warner Bros and Pokémon Co did not return requests for comment.</p> 
<p>David Karpf, an associate professor at George Washington University’s School of Media and Public Affairs, said he had viewed videos of copyrighted characters promoting cryptocurrency scams. He said it’s clear OpenAI’s safeguards and mitigations for Sora aren’t working.</p> 
<figure class="element element-atom"> <gu-atom data-atom-id="284ae473-6a2d-4851-8f66-8e3b85b55f39" data-atom-type="media"> 
  <div>
   <iframe frameborder="0" allowfullscreen="true" src="https://www.youtube-nocookie.com/embed/T2jf6Gdehzc?showinfo=0&amp;rel=0"></iframe>
  </div>
 </gu-atom> 
</figure> 
<p>“The guardrails are not real if people are already creating copyrighted characters promoting fake crypto scams,” Karpf said. “In 2022, [the tech companies] would have made a big deal about how they were hiring content moderators … In 2025, this is the year that tech companies have decided they don’t give a shit.”</p> 
<h2>Copyright, copycat</h2> 
<p>Shortly before OpenAI released Sora 2, the company reached out to talent agencies and studios, alerting them that if they didn’t want their copyrighted material replicated by the video generator, they would have to opt out, according to a <a href="https://www.wsj.com/tech/ai/openais-new-sora-video-generator-to-require-copyright-holders-to-opt-out-071d8b2a?gaa_at=eafs&amp;gaa_n=ASWzDAgBXOloXWv_e-MOQbM93O8rXfsAF3tmLty9_t2ixm5b9pHXdxrOBAeEUDVgjec%3D&amp;gaa_ts=68deb73b&amp;gaa_sig=Up1vP89aWPLJ57z6eSJYocKZ4F0l5DMiLh19IjEagWl6ddUg2n_hKnX8aw8kjmMfCwSogb-SHRbUuulHDg2Z4Q%3D%3D">report by the Wall Street Journal</a>.</p> 
<p>OpenAI told the Guardian that content owners can flag copyright infringement using a “copyright disputes form”, but that individual artists or studios cannot have a blanket opt-out. Varun Shetty, OpenAI’s head of media partnerships, said: “We’ll work with rights holders to block characters from Sora at their request and respond to takedown requests.”</p> 
<p>Emily Bender, a professor at the University of Washington and <a href="https://www.theguardian.com/books/2025/may/19/the-ai-con-by-emily-m-bender-and-alex-hanna-review-debunking-myths-of-the-ai-revolution">author of the book The AI Con</a>, said Sora is creating a dangerous situation where it’s “harder to find trustworthy sources and harder to trust them once found”.</p> 
<p>“Synthetic media machines, whether designed to extrude text, images or video, are a scourge on our information ecosystem,” Bender said. “Their outputs function analogously to an oil spill, flowing through connections of technical and social infrastructure, weakening and breaking relationships of trust.”</p> 
<p><em>Nick Robins-Early contributed reporting</em></p> 
<aside class="element element-rich-link element--thumbnail"> 
 <p> <span>Related: </span><a href="https://www.theguardian.com/technology/ng-interactive/2025/oct/02/ai-children-parenting-creativity">‘My son genuinely believed it was real’: Parents are letting little kids play with AI. Are they wrong?</a> </p> 
</aside> 
<figure class="element element-atom"> <gu-atom data-atom-id="ea05a110-2f0f-41ea-ba0a-8d9189dbddb7" data-atom-type="guide"> 
  <div>
   <div class="atom-Guide">
    <p><strong></strong></p>
    <p></p>
    <p>The best public interest journalism relies on first-hand accounts from people in the know.</p>
    <p></p>
    <p>If you have something to share on this subject, you can contact us confidentially using the following methods.</p>
    <p></p>
    <p><strong>Secure Messaging in the Guardian app</strong></p>
    <p></p>
    <p>The Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.</p>
    <p></p>
    <p>If you don't already have the Guardian app, download it (<a href="https://apps.apple.com/app/the-guardian-live-world-news/id409128287">iOS</a>/<a href="https://play.google.com/store/apps/details?id=com.guardian">Android</a>) and go to the menu. Select ‘Secure Messaging’. </p>
    <p></p>
    <p><strong>SecureDrop, instant messengers, email, telephone and post</strong></p>
    <p></p>
    <p>If you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our <a href="https://www.theguardian.com/securedrop">SecureDrop platform</a>.</p>
    <p></p>
    <p>Finally, our guide at <a href="https://www.theguardian.com/tips">theguardian.com/tips</a>&nbsp;lists several ways to contact us securely, and discusses the pros and cons of each.&nbsp;</p>
    <p></p>
   </div>
  </div>
 </gu-atom> 
</figure>