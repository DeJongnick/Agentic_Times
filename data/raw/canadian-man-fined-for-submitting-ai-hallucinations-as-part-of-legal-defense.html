<h1>Canadian man fined for submitting AI hallucinations as part of legal defense</h1>
<div><strong>Date :</strong> 2025-10-15T16:31:31Z &nbsp; | &nbsp; <strong>Auteur :</strong> Leyland Cecco in Toronto &nbsp; | &nbsp; <strong>Journal :</strong> World news</div>
<p>A <a href="https://www.theguardian.com/world/quebec">Quebec</a> man has been ordered to pay C$5,000 (US$3,562) for submitting artificial intelligence hallucinations as part of his legal defense, a move the judge warned was “highly reprehensible” and threatened to undermine integrity in the legal system.</p> <p>Justice Luc Morin of Quebec superior court levied the fine on Jean Laprade in a <a href="https://citoyens.soquij.qc.ca/php/decision.php?ID=21B262E00E271D3FA17BC6D26D8D0603&amp;page=2">decision released on 1 October</a>, capping a legal saga the judge said “contains several elements worthy of a successful movie script”, including a “hijacked plane passing through several complacent airports”, Interpol red alerts and the “inappropriate use of artificial intelligence” by Laprade.</p> <p>At issue was a deal for three helicopters and an airplane that Laprade had brokered while in the west African country of <a href="https://www.theguardian.com/world/guinea">Guinea</a>. An error in the contract mistakenly awarded the businessperson an aircraft that was far more valuable than the one agreed upon.</p> <p>Laprade was accused of “diverting” it to Quebec and fended off efforts to recover the plane by two aviation companies. A 2021 decision by the Paris international arbitration chamber ordered him to pay C$2.7m for the aircraft, which has been sitting at the Sherbrooke airport under a seizure order since 2019.</p> <p>In his defense, Laprade submitted several pieces of information to the court that had been fabricated by artificial intelligence, including “eight instances of non-existent citations, decisions not rendered, references without purpose and inconsistent conclusions”.</p> <p>Morin noted in his decision that the courts had previously warned the legal community in 2023 about the use of artificial intelligence, issuing a notice that information generated by AI must be subject to “rigorous human control”.</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/world/2024/feb/29/canada-lawyer-chatgpt-fake-cases-ai">Canada lawyer under fire for submitting fake cases created by AI chatbot</a> </p> </aside>  <p>Laprade’s attempt to “mislead the opposing party and the Tribunal by producing fictitious extracts” of case law represented a “serious breach”, Morin wrote. “It should be remembered that the filing of a procedure remains a solemn act that can never be taken lightly.”</p> <p>Laprade apologized and admitted his submissions were “probably not perfect” but said the use of artificial intelligence was key in his defense.</p> <p>Morin noted that Laprade, who is 74 and “who has clearly lived a very interesting life”, faced a challenge in defending himself without legal counsel.</p> <p>“While the court is sensitive to the fact that Mr Laprade’s intention was to defend himself to the best of his abilities using artificial intelligence, his conduct remains highly reprehensible,” wrote the judge. “He must bear alone all the opprobrium resulting from quotations ‘hallucinated’ by artificial intelligence on which he relied to generate his contestation.”</p> <p>Morin also acknowledged both the power and lure of artificial intelligence, which he said could soon transform the courts.</p> <p>“Although its intoxicating promises are matched only by the fears associated with its inappropriate use, artificial intelligence will seriously test the vigilance of the courts for years to come.” </p>