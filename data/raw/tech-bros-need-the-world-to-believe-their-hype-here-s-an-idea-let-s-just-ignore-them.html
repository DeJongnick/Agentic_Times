<h1>Tech bros need the world to believe their hype. Here’s an idea – let’s just ignore them</h1>
<div><strong>Date :</strong> 2025-10-19T14:00:19Z &nbsp; | &nbsp; <strong>Auteur :</strong> Pip Finkemeyer &nbsp; | &nbsp; <strong>Journal :</strong> Books</div>
<p>There is a “hype cycle” that maps the euphoria and hysteria generated by new technology and then the consequent plunge into the “trough of disillusionment” when it fails to deliver on its promises.</p> <p>The <a href="https://www.theguardian.com/technology/2002/jan/03/internetnews.onlinesupplement1">Gartner Hype Cycle</a> was coined in 1995, timely for the dotcom boom, and now traces the trajectory of artificial intelligence. We are at the “peak of inflated expectations” before we nosedive into that aforementioned disillusionment. Some would say we are already in freefall, with companies struggling to convert their investments into productivity.</p> <p>Most creatives, workers, humans (actually, anyone except those who have invested the trillions into AI and will lose a lot of money from the inevitable puncturing of the hype) would welcome that freefall, that collective loss of belief. </p> <p>As a writer, but more so as a tech worker, I’ve seen first-hand people’s propensity to believe in things they don’t understand, perhaps specifically because they don’t understand them. I once had a boss who spoke about my work in hushed and reverent tones because I was working on something that simply sounded a lot like AI – it was IA, or information architecture, which has nothing to do with AI except that it uses the same letters.</p> <p>At times I think it’s kind of beautiful, the way enough kind-hearted people will always believe some magical and sublime invention is coming to save us. But this hope and optimism is what big tech is counting on. The hype is boosted by the opposite opinions too, ones that speak to a powerful and all-knowing dystopian force coming to us straight out of science fiction novels. If hype feeds on our positivity (wanting to believe in something) and our negativity (our survival instinct to scan the horizon for predators) then what are we to do?</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/books/2023/jun/03/sad-girl-novel-author-pip-finkemeyer-on-critiquing-sad-girl-novels-it-has-to-have-a-heart">Sad Girl Novel author Pip Finkemeyer on critiquing sad girl novels: ‘It has to have a heart’</a> </p> </aside>  <p>I’d like to entertain the idea of a kind of collective ignoring, like students ignoring a disruptive class clown in hopes they quieten down faster. But class clown might be too likable and innocent as a stand-in for a collective of men with the highest concentration of power in the world. Also, class clowns are funny. </p> <p>So, do we really have the power to do that? Just ignore them?</p> <p>Tech is a speculative industry, money is made not on the product working, being any good or, in many cases, even making it to market. The money is made by making us <em>believe</em>. Or to get more granular on that idea (as the tech bros love to say), the money is made by making investors believe, not that the product will work, but that individuals and society as a whole can be made to also <em>believe</em>, if they put enough money behind the idea, that a certain type of future is inevitable. When we submit to their ideas, that’s when they get their return on investment. </p> <p>There are so many ways resisting big tech is difficult. But there is one simple way to resist that can’t be taken away from you and it might sound naive: just ignore it and its stories about your life.</p> <p>As a fiction writer, of course I am interested in the practice of making people believe something I just pulled out of thin air. If Ken’s job is “beach”, mine is “make believe”. As a tech worker, I spent the first Trump presidency working on a product to help people in the US learn Mexican Spanish. Now I look back with longing at the period in the 2010s when Washington at least pretended it had control over Silicon Valley, not the other way around. </p> <p>The inversion point for that relationship between tech and politics is what drives the scandal in my novel One Story. During this era, we all (or enough of us) believed in the connection that social media would bring us, and flocked to those platforms. In hindsight, we surely see how much the opposite is actually true, now that we have all the data. Or rather, they do, and they used it to change the course of democracy. </p> <p>But with AI, we all (or enough of us) are believing all over again, a new story from many of the same men.</p> <p>My first novel was <a href="https://www.theguardian.com/technology/2025/mar/25/no-consent-australian-authors-livid-that-meta-may-have-used-their-books-to-train-ai-ntwnfb">pirated by Meta to feed its large language model</a>, along with almost every other living author you know. I’m not saying ignore what tech companies do (of course we need to actively fight to protect artists’ intellectual property, and to protect so much more), I’m saying ignore what they say. If we took power out of their narrative that it’s all inevitable because what’s most important is “prosperity in the tech world”, it would make the fight easier.</p>    <p>I’ve been designing software alongside the rise of AI. Both of my jobs are ones where I should feel threatened. And I have felt that sense of doom, of course, because I am a human, not a piece of software simulating one. Coincidentally, this simple undeniable fact, that I am a human being, is what makes me a better writer and designer, and bolsters me in my endeavour to ignore generative AI, and the idea that it might one day start writing amazing novels.</p> <p>I think all discerning readers would agree, looking at the quality of text AI produces, that if some magical and sublime invention is really coming to save you, it is more likely to be a piece of literature than a piece of software.</p> <ul> <li><p><em>Pip Finkemeyer is the author of One Story ($34.99), out now from Ultimo Press</em></p></li> </ul>