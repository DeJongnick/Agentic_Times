<h1>People interviewed by AI for jobs face discrimination risks, Australian study warns</h1>
<div><strong>Date :</strong> 2025-05-13T15:00:44Z &nbsp; | &nbsp; <strong>Auteur :</strong> Josh Taylor Technology reporter &nbsp; | &nbsp; <strong>Journal :</strong> Australia news</div>
<p>Job candidates being interviewed by AI recruiters risk being discriminated against if they speak with accents, or are living with a disability, a new study has warned.</p> <p>This month, videos of job candidates interacting with at-times faulty AI video interviewers as part of the recruitment process have been widely shared on TikTok.</p>  <figure class="element element-embed" data-alt="AI video">  <iframe class="fenced" srcdoc="&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;blockquote class=&quot;tiktok-embed&quot; cite=&quot;https://www.tiktok.com/@its_ken04/video/7499859438732414251&quot; data-video-id=&quot;7499859438732414251&quot; style=&quot;max-width: 605px;min-width: 325px;&quot; &gt; &lt;section&gt; &lt;a target=&quot;_blank&quot; title=&quot;@its_ken04&quot; href=&quot;https://www.tiktok.com/@its_ken04?refer=embed&quot;&gt;@its_ken04&lt;/a&gt; It was genuinely so creepy and weird. Please stop trying to be lazy and have AI try to do YOUR JOB!!! It gave me the creeps so bad &lt;a title=&quot;fyp&quot; target=&quot;_blank&quot; href=&quot;https://www.tiktok.com/tag/fyp?refer=embed&quot;&gt;#fyp&lt;/a&gt; &lt;a target=&quot;_blank&quot; title=&quot;â™¬ original sound - Its Ken ğŸ¤&quot; href=&quot;https://www.tiktok.com/music/original-sound-7499859603190975278?refer=embed&quot;&gt;â™¬ original sound - Its Ken ğŸ¤&lt;/a&gt; &lt;/section&gt; &lt;/blockquote&gt; &lt;script async src=&quot;https://www.tiktok.com/embed.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;"></iframe> </figure>  <p>The use of AI video recruitment has grown in recent years. HireVue, an AI recruitment software company used by many employers, reported in February that, among 4,000 employers surveyed worldwide, AI use in hiring had risen from 58% in 2024 to 72% in 2025.</p> <ul> <li><p><strong><a href="https://www.theguardian.com/email-newsletters?CMP=copyembed">Sign up for Guardian Australiaâ€™s breaking news email</a></strong></p></li> </ul> <p>Australian research <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/jols.12535">published this month</a> estimates the use is significantly lower â€“ about 30% in Australian organisations â€“ but expected to grow in the next five years.</p> <p>However, the paper, by Dr Natalie Sheard, a University of Melbourne law school researcher, warns the use of AI hiring systems to screen and shortlist candidates risks discriminating against applicants, due to biases introduced by the limited datasets the AI models were trained on.</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/technology/2025/may/09/crowdstrike-to-cut-jobs-and-use-ai">â€˜Tone deafâ€™: US tech company responsible for global IT outage to cut jobs and use AI</a> </p> </aside>  <p>In her research, Sheard interviewed 18 human resources professionals in Australia on their use of AI in recruitment. Of these, 13 had used AI recruitment systems in their companies, with the most common tool being CV analysis systems, followed by video interviewing systems.</p> <p>Datasets based on limited information that often favours American data over international data presents a risk of bias in those AI systems, Sheard said. One AI systems company featured in Sheardâ€™s research, for example, has said only 6% of its job applicant training data came from Australia or New Zealand, and 36% of the job applicants in the training data were white.</p> <p>The same company has said, according to the paper, that its word error rate for transcription of English-language speakers in the US is less than 10%, on average. However, when testing non-native English speakers with accents from other countries, that error rate increases to between 12 and 22%. The latter error rate is for non-native English speakers from China.</p>  <figure class="element element-embed" data-alt="AI video">  <iframe class="fenced" srcdoc="&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;blockquote class=&quot;tiktok-embed&quot; cite=&quot;https://www.tiktok.com/@petobsessed777/video/7499996920622992682&quot; data-video-id=&quot;7499996920622992682&quot; style=&quot;max-width: 605px;min-width: 325px;&quot; &gt; &lt;section&gt; &lt;a target=&quot;_blank&quot; title=&quot;@petobsessed777&quot; href=&quot;https://www.tiktok.com/@petobsessed777?refer=embed&quot;&gt;@petobsessed777&lt;/a&gt; Should I email them? I was expecting a real human. They didnt tell me ahead of time theyd use AI. &lt;a title=&quot;ai&quot; target=&quot;_blank&quot; href=&quot;https://www.tiktok.com/tag/ai?refer=embed&quot;&gt;#ai&lt;/a&gt; &lt;a target=&quot;_blank&quot; title=&quot;â™¬ original sound - Freddie&quot; href=&quot;https://www.tiktok.com/music/original-sound-7499997002376104750?refer=embed&quot;&gt;â™¬ original sound - Freddie&lt;/a&gt; &lt;/section&gt; &lt;/blockquote&gt; &lt;script async src=&quot;https://www.tiktok.com/embed.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;"></iframe> </figure>  <p>â€œThe training data will come from the country where theyâ€™re built â€“ a lot of them are built in the US, so they donâ€™t reflect the demographic groups we have in Australia,â€ Sheard said.</p> <p>Research participants told Sheard that non-native English speakers or those with a disability affecting their speech could find their words not being transcribed correctly, and would then not be rated highly by the recruitment algorithm.</p> <p>This prompted two of the participants to seek reassurance from their software vendor that it did not disadvantage candidates with accents. Sheard said they were given reassurances that the AI was â€œreally good at understanding accentsâ€ but no evidence was provided to support this.</p> <p>Sheard said there was little to no transparency about the AI interview systems used, for potential recruits, the recruiter, or the employer.</p> <p>â€œThis is the problem. In a human process, you can go back to the recruiter and ask for feedback, but what I found is recruiters donâ€™t even know why the decisions have been made, so they canâ€™t give feedback,â€ she said.</p> <p>â€œThatâ€™s a problem for job seekers â€¦ Itâ€™s really hard to pick where liability lies, but absolutely vendors and employers are legally liable for any discrimination by these systems.â€</p> <p>No case of AI discrimination had yet reached the courts in Australia, Sheard said, with any instances of discrimination needing to first go to the Australian Human Rights Commission.</p> <p>In 2022, the federal merit protection commissioner <a href="https://www.mpc.gov.au/sites/default/files/2022-10/Annual%20Report%202021-22.pdf">revealed</a> 11 promotion decisions in Services Australia in the previous year had been overturned, after the agency outsourced the process to a recruitment specialist that used AI automated selection techniques, including psychometric testing, questionnaires and self-recorded video responses.</p> <p>It was found that the selection process â€œdid not always meet the key objective of selecting the most meritorious candidatesâ€.</p> <p>Sheard said the returned Albanese Labor government should consider a specific AI act to regulate the use of AI, and potentially strengthen existing discrimination laws to guard against AI-based discrimination.</p> <p>â€¢ This article was amended on 14 May 2025. A previous version incorrectly stated job candidates risk being discriminated against if they donâ€™t have American accents. The previous version also incorrectly stated 23 human resources professionals were interviewed and 33% of the job applicants in the training data were white.</p>