<h1>The Guardian view on DeepSeek and a global AI race: geopolitics, innovation and the rise of chaos</h1>
<div><strong>Date :</strong> 2025-01-26T17:25:55Z &nbsp; | &nbsp; <strong>Auteur :</strong> Editorial &nbsp; | &nbsp; <strong>Journal :</strong> Opinion</div>
<p>Eight years ago, Vladimir Putin proclaimed that mastering artificial intelligence (AI) would make a nation the “<a href="https://www.theverge.com/2017/9/4/16251226/russia-ai-putin-rule-the-world">ruler of the world</a>”. Western tech sanctions after Russia’s invasion of Ukraine should have dashed his ambitions to lead in AI by <a href="https://carnegieendowment.org/posts/2020/08/developing-artificial-intelligence-in-russia-objectives-and-reality?lang=en&amp;amp;center=russia-eurasia">2030</a>. But that might be too hasty a judgment. Last week, the Chinese lab DeepSeek unveiled R1, an AI that <a href="https://www.nature.com/articles/d41586-025-00229-6">analysts</a> say rivals OpenAI’s top reasoning model, o1. Astonishingly, it matches o1’s capabilities while using a fraction of the computing power – and at a tenth of the cost. Predictably, one of Mr Putin’s first <a href="https://www.reuters.com/technology/artificial-intelligence/putin-orders-russian-government-top-bank-develop-ai-cooperation-with-china-2025-01-01/">moves</a> in 2025 was to align with China on AI development. R1’s launch seems no coincidence, coming just as Donald Trump backed OpenAI’s $500bn <a href="https://www.cbsnews.com/news/trump-stargate-ai-openai-softbank-oracle-musk/">Stargate</a> plan to outpace its peers. OpenAI has singled out DeepSeek’s parent, <a href="https://techcrunch.com/2025/01/20/deepseek-claims-its-reasoning-model-beats-openais-o1-on-certain-benchmarks/?utm_source=dlvr.it&amp;amp;utm_medium=bluesky">High Flyer Capital</a>, as a potential threat. But at least three <a href="https://arstechnica.com/ai/2025/01/china-is-catching-up-with-americas-best-reasoning-ai-models/">Chinese</a> labs claim to rival or surpass OpenAI’s achievements.</p> <p>Anticipating tighter US chip sanctions, Chinese companies <a href="https://www.nbcsandiego.com/news/business/money-report/scale-ai-ceo-says-china-has-quickly-caught-the-u-s-with-the-deepseek-open-source-model/3732443/">stockpiled</a> critical processors to ensure their AI models could advance despite restricted access to hardware. DeepSeek’s success underscores the ingenuity born of necessity: lacking massive datacentres or powerful specialised chips, it achieved breakthroughs through better data curation and optimisation of its model. Unlike proprietary systems, R1’s source code is public, allowing anyone competent to modify it. Yet its openness has limits: <a href="https://techcrunch.com/2025/01/20/deepseek-claims-its-reasoning-model-beats-openais-o1-on-certain-benchmarks/?utm_source=dlvr.it&amp;amp;utm_medium=bluesky">overseen</a> by China’s internet&nbsp;regulator, R1 conforms to “core socialist values”. Type in Tiananmen Square or Taiwan, and the&nbsp;model&nbsp;reportedly shuts down the conversation.</p> <p>DeepSeek’s R1 highlights a broader debate over the future of AI: should it remain locked behind <a href="https://www.forbes.com/sites/johnwerner/2024/11/06/open-ai-systems-lag-behind-proprietary-and-closed-models/">proprietary</a> walls, controlled by a few big corporations, or be “<a href="https://www.zdnet.com/article/deepseeks-new-open-source-ai-model-can-outperform-o1-for-a-fraction-of-the-cost/">open sourced</a>” to foster global innovation? One of the <a href="https://www.politico.com/news/2025/01/22/trump-ai-plan-elon-musk-altman-slapfight-00200075">Biden</a> administration’s final acts was to clamp down on open-source AI for national security reasons. Freely accessible, highly capable AI could empower bad actors. Interestingly, Mr Trump later rescinded the order, arguing that stifling open-source development harms innovation. Open-source advocates, <a href="https://www.nytimes.com/2024/05/29/technology/what-to-know-open-closed-software.html">like Meta</a>, have a point when crediting recent AI breakthroughs to a decade of freely sharing code. Yet the risks are undeniable: in February, OpenAI shut down accounts linked to state-backed hackers from China, Iran, Russia and North Korea who used its tools for phishing and malware campaigns. By summer, OpenAI had <a href="https://www.chinatalk.media/p/openai-pulls-the-plug-on-china">halted</a> services in those nations.</p> <p>Superior US control over critical AI hardware in the future may give rivals little chance to compete. OpenAI offers “<a href="https://archive.ph/ElqTU#selection-829.265-829.357">structured access</a>”, controlling how users can interact with its models. But DeepSeek’s success suggests that open-source AI can drive <a href="https://www.ft.com/content/c99d86f0-2d17-49d0-8dc6-9662ed34c831">innovation</a> through creativity, rather than brute processing power. The contradiction is clear: open-source AI democratises technology and fuels&nbsp;progress, but it also enables exploitation by malefactors. Resolving this tension between innovation and security demands an <a href="https://www.lemonde.fr/en/international/article/2025/01/15/india-to-co-chair-paris-ai-summit-in-february_6737072_4.html">international framework</a> to prevent misuse.</p> <p>The AI race is as much about global influence as technological dominance. Mr Putin urges developing nations to unite to <a href="https://www.reuters.com/technology/artificial-intelligence/russia-teams-up-with-brics-create-ai-alliance-putin-says-2024-12-11/">challenge</a> US tech leadership, but without global regulation, there are immense risks in a frantic push for AI supremacy. It would be wise to pay heed to <a href="https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years">Geoffrey Hinton</a>, the AI pioneer and Nobel laureate. He warns that the breakneck pace of <a href="https://www.nytimes.com/2025/01/23/technology/ai-test-humanitys-last-exam.html">progress</a> shortens the odds of catastrophe. In the race to dominate this technology, the greatest risk isn’t falling behind. It’s losing control entirely. </p>