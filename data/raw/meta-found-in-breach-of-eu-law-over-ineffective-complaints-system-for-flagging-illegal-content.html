<h1>Meta found in breach of EU law over ‘ineffective’ complaints system for flagging illegal content</h1>
<div><strong>Date :</strong> 2025-10-24T11:12:59Z &nbsp; | &nbsp; <strong>Auteur :</strong> Robert Booth and Lisa O’Carroll &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>Instagram and Facebook have breached EU law by failing to provide users with simple ways to complain or flag illegal content, including child sexual abuse material and terrorist content, the European Commission has said.</p> <p>In a preliminary finding on Friday, the EU’s executive body said Meta, the $1.8tn (£1.4tn) California company that runs Instagram and Facebook, had introduced unnecessary steps in processes for users to submit reports.</p> <p>It said both platforms appeared to use deceptive design – known as “dark patterns” – in the reporting mechanism in a way that could be “confusing and dissuading” to users.</p> <p>The commission found this amounted to a breach of the company’s obligations under the <a href="https://www.theguardian.com/world/2023/aug/25/how-the-eu-digital-services-act-affects-facebook-google-and-others">EU-wide Digital Services Act</a> (DSA), and meant that “Meta’s mechanisms to flag and remove illegal content may be ineffective”. Meta denies it has breached the act.</p> <p>“When it comes to Meta, neither Facebook nor Instagram appear to provide a user-friendly and easily accessible ‘notice and action’ mechanism for users to flag illegal content such as child sexual abuse material and terrorist content,” the commission said.</p> <p>A senior EU official said the case was not only about illegal content, but also about freedom of speech and “moderation that has gone too far”. In the past, Facebook has been accused of “shadow banning” users <a href="https://www.theguardian.com/technology/2023/oct/18/instagram-palestine-posts-censorship-accusations">on issues such as Palestine</a>, meaning their content is demoted by the algorithm.</p> <p>The current mechanisms for complaints were “too difficult for users to go through to the end”, resulting not just in ineffectiveness but a disincentive for users to get in touch, the official said.</p> <p>Campaigners have continued to allege safety shortcomings in some of Meta’s products. Last month, a Meta whistleblower, Arturo Béjar, <a href="https://www.theguardian.com/technology/2025/sep/25/instagram-risk-children-safety-tools-meta">published research</a> he said showed that the majority of new safety tools rolled out on Instagram were ineffective, leaving children under 13 not safe on the platform.</p> <p>Meta rejected the report’s findings and said parents had robust tools at their fingertips. The company introduced mandatory teen accounts on Instagram in September 2024, and <a href="https://www.theguardian.com/technology/2025/oct/14/instagram-parental-guidance-pg-13-age-rating-system-meta">it said this month</a> it would adopt a version of the PG-13 cinema rating system to give parents stronger controls over their teenagers’s use of the social media platform.</p> <p>The commission also said Meta made things difficult for users whose content had been blocked or their accounts suspended. It found the decision appeal mechanism did not appear to allow users to provide explanations or evidence to substantiate their appeals, limiting its effectiveness.</p> <p>The commission said simplification of the feedback system would also help the platforms eliminate fake news such as the <a href="https://x.com/adrianweckler/status/1980755255089377553">deepfake video in Ireland</a> claiming the leading presidential election candidate, <a href="https://www.theguardian.com/world/2025/oct/23/catherine-connolly-the-outspoken-leftwinger-set-to-be-irelands-next-president">Catherine Connolly</a>, was pulling out of <a href="https://www.theguardian.com/world/2025/oct/24/ireland-votes-for-next-president-as-polls-predict-landslide-for-catherine-connolly">Friday’s election</a>.</p> <p>The investigation, which is ongoing, was carried out in cooperation with Coimisiún na Meán, the Irish digital services coordinator responsible for regulating the platforms, whose EU headquarters are in Dublin.</p> <p>The commission also made a preliminary finding that TikTok and Meta were in breach of their obligation to grant researchers adequate access to public data that could be used to check on how far minors are exposed to illegal or harmful content. It said researchers were often left with partial or unreliable data.</p> <p>“Allowing researchers access to platforms’ data is an essential transparency obligation under the DSA, as it provides public scrutiny into the potential impact of platforms on our physical and mental health,” the commission said.</p> <p>The preliminary findings allow the platforms time to comply with the commission’s demands. If they do not, they face a fine of up to 6% of total worldwide annual turnover, with periodic penalty payments to compel compliance.</p> <p>Henna Virkkunen, the commission’s executive vice-president for tech sovereignty, security and democracy, said: “Our democracies depend on trust. That means platforms must empower users, respect their rights and open their systems to scrutiny.</p> <p>“The DSA makes this a duty, not a choice. With today’s actions, we have now issued preliminary findings on researchers’ access to data to four platforms. We are making sure platforms are accountable for their services, as ensured by EU law, towards users and society.”</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/global-development/ng-interactive/2025/oct/23/give-me-shelter-protecting-trafficked-children-in-the-us-documentary">Give me shelter: protecting trafficked children in the US - documentary</a> </p> </aside>  <p>A Meta spokesperson said: “We disagree with any suggestion that we have breached the DSA, and we continue to negotiate with the European Commission on these matters. In the European Union, we have introduced changes to our content reporting options, appeals process, and data access tools since the DSA came into force and are confident that these solutions match what is required under the law in the EU.”</p> <p>TikTok said it was not possible to fully share data about its platform with researchers without breaking separate <a href="https://www.theguardian.com/technology/2018/may/21/what-is-gdpr-and-how-will-it-affect-you">GDPR data protection rules.</a></p> <p>“TikTok is committed to transparency and values the contribution of researchers to our platform and the wider industry,” a spokesperson said. “We have made substantial investments in data sharing and almost 1,000 research teams have been given access to data through our research tools to date.</p> <p>“We are reviewing the European Commission’s findings, but requirements to ease data safeguards place the DSA and GDPR in direct tension.”</p> <p>The company urged regulators to “provide clarity on how these obligations should be reconciled”.</p>