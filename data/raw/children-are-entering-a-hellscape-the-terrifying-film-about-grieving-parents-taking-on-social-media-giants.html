<h1>‘Children are entering a hellscape’: the terrifying film about grieving parents taking on social media giants</h1>
<div><strong>Date :</strong> 2025-08-04T15:00:36Z &nbsp; | &nbsp; <strong>Auteur :</strong> Cath Clarke &nbsp; | &nbsp; <strong>Journal :</strong> Film</div>
<p>In 2020, Amy Neville found her 14-year-old son Alexander dead in his bedroom. He had taken what he thought was an oxycodone pill, bought – according to Neville – from a drug dealer he met on Snapchat. The pill was a fake, laced with fentanyl. Four years later, his mum stood up in the California high school where Alex would have been a student to warn other parents and teenagers about social media. “We give our kids these smartphones. We let them have these apps. And that is the equivalent of dropping them off in the worst neighbourhood in our area.”</p> <p>Neville is featured alongside other bereaved parents in Can’t Look Away, a terrifying new documentary about kids and social media directed by Matthew O’Neill and Perri Peltz, based on extensive investigative reporting by Bloomberg News journalist Olivia Carville. It follows American families who are filing lawsuits against social media companies and campaigning for stricter legislation; they are represented by the Social Media Victims Law Center, a crusading legal firm run Matthew Bergman, a lawyer so charismatic he could probably play himself in a Hollywood movie.</p>  <aside class="element element-pullquote element--inline"> <blockquote> <p>The directors ask if the kids have ever watched a suicide. Almost every hand goes up</p> </blockquote> </aside>  <p>The conversation around teenagers and social media has evolved beyond kids using their phones at the table. <a href="https://www.theguardian.com/books/2024/mar/21/the-anxious-generation-by-jonathan-haidt-a-pocket-full-of-poison">In his 2024 bestseller The Anxious Generation</a>, Jonathan Haidt warned of the links between <a href="https://www.theguardian.com/society/ng-interactive/2025/jun/07/jonathan-haidt-anxious-generation-smartphones">young people’s mental health and smartphones</a>. Last month, the technology secretary Peter Kyle apologised for the delay in legislation to keep children safe online. <a href="https://www.theguardian.com/technology/2025/aug/01/how-australia-under-16s-social-media-ban-enforced-tiktok-instagram-facebook-exempt-platforms">Australia plans to ban social media for under 16s from December</a>.</p> <p>In Can’t Look Away, the agony on parents’ faces as they tell their stories, and relive the trauma, is hard to watch. Toney and Brandy Roberts filed a lawsuit against Meta over the death of their 14-year-old daughter Englyn in 2020; she killed herself after watching a video of a mock-hanging on Instagram. “The social media companies know that our children are so vulnerable,” Brandy tells the camera. “I feel that the only way that they’re going to be forced to change is through a lawsuit. So that’s why we’re joining this fight.”</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/lifeandstyle/2024/jan/16/online-harms-social-media-lawsuits">‘The tide has turned’: why parents are suing US social media firms after their children’s death</a> </p> </aside>  <p>When I talk to the film’s directors before Can’t Look Away’s UK premiere, they do not mince their words. O’Neill says he previously had no idea how extreme the content that children are exposed to on social media is. “It’s so much more than just addiction, or screen time, or wasting time. What young people see is so different because of the algorithms. What they’re being fed, what they can’t look away from, this is not what they’re searching for. Children are essentially entering into a hellscape that adults don’t know about.”</p>       <figure class="element element-video" data-canonical-url="https://www.youtube.com/watch?v=kSmyNHKMYB4"                                                                        >  <iframe height="480" width="854" src="https://www.youtube-nocookie.com/embed/kSmyNHKMYB4?wmode=opaque&feature=oembed" frameborder="0" allowfullscreen ></iframe> </figure>   <p>Algorithms decide what you see on social media, based in part on what you have previously liked or commented on, and how much time you’ve spent on other posts. If you linger on a piece of content, the algorithm will feed you more of the same. What that means is that teenagers don’t have to actively search for harmful material for it to appear in their feed. A 13-year-old girl might look for healthy eating advice and end up down a rabbit hole of pro-anorexia content. “It can very quickly turn very dark,” says O’Neill.</p> <p>Mason Edens was 16 when he broke up with his girlfriend; normal teenage stuff his mum Jennie DeSerio thought. In his heartache, Mason turned to TikTok, searching for phrases such as: “My girlfriend broke up with me.” In the film, his mum plays one of the depressing videos that ended up in his feed. It shows a gun in a hand, then an image of blood splatter and the words: “My hand. My head.” Mason killed himself in November 2022. Jennie doesn’t believe that he’d ever searched for the term “suicide” on TikTok. </p> <p>O’Neill says he was shocked by Mason’s feed: “This is not someone crying. It’s not just sad music. It is an image of a gun going into a hand with the exhortation to blow your effing head off. That is not content that a product should be feeding to a child. I think we could all broadly agree on that as a society.”</p> <p>Is it possible, I ask, for the social media companies to filter out harmful content? “If Meta knows what I want to buy before I buy it, there’s no way they can’t figure out how to make sure children aren’t fed content that demonstrates how to die by suicide.” </p>    <p>After screenings of Can’t Look Away, the film-makers often ask the kids in the audience if they have ever watched a suicide on social media. “Almost all the hands go up,” says co-director Peltz.</p> <p>In America, 95% of 13 to 17-year-olds use social media. In 2022, social media companies made an estimated $11bn from advertising directed to under 18s in the US. The longer kids are glued to it, the more billions the companies make, which means there is a huge incentive to design sticky algorithms, says Peltz. “Why are they feeding children material that they can’t look away from? Because it keeps children on their sites for as long as possible. And we know from whistleblowers that that is a business plan. This is not an accident. They are prioritising time on screen over safety.”</p> <p>The film features interviews with such whistleblowers, who say companies have been warned that their products harm children. Arturo Béjar held senior positions at Facebook and Instagram, and became increasingly alarmed by their parent company Meta’s own research. In one poll, one in eight 13 to 15-year-olds said they had received an unwanted sexual advance on Instagram in the past week. Béjar emailed his concerns to Mark Zuckerberg, Sheryl Sandberg and other top executives. He says he never received a reply.</p> <p>Can’t Look Away tells the heart-breaking story of Jordan DeMay, a popular, outgoing 17-year-old from Michigan who killed himself after being blackmailed in a sextortion scam. In March 2022, he received a message on Instagram from someone he thought was a girl his own age. After some flirting, Jordan sent her nude photographs. Immediately, the threats started: send money or we’ll share the photos with your friends and family. Less than six hours after the first of these messages, Jordan was dead.</p> <p>Sextortion is one of the fastest growing cybercrimes. Peltz is keen to share with parents the advice she has picked up from several professionals about how to protect children. “Talk to your child. Tell them, ‘If this ever happens to you, do not be afraid to come to us.’ It’s very specific advice that can make a major difference.”</p>    <p>Can’t Look Away ends with some real-life courtroom drama in Los Angeles. Amy Neville, the woman whose son took the fake oxycodone pill, is the lead plaintiff in a case against Snapchat by parents whose children died or were injured after allegedly buying fentanyl-laced drugs. Their lawsuit claims that Snapchat’s design makes it an ideal marketplace to sell illegal drugs, with its disappearing messages that make it difficult for police to trace illegal activity. Another feature is Quick Add, which suggests other users to add. Laura Marquez-Garrett is a lawyer at the Social Media Victims Law Center and explains how it works. “[A dealer will] just find one high school kid in your area. You add them, and then you add all their friends, and then you add <em>their</em> friends.”</p> <p>In a courtroom showdown, Snap Inc’s defence relies on a piece of US legislation drafted before Zuckerberg hit puberty. Section 230 of the Communications Decency Act of 1996 has for years acted as a shield (or a get-out-of-jail card, depending on your perspective) protecting social media companies from liability for user-generated content posted on their platforms. In court, Snap Inc’s attorney describes the platform as a tech-service provider, like a phone company. You wouldn’t sue a phone company if a drug deal was made over the phone. The back-and-forth between the lawyers and the judge is a gripping intellectual tennis match.</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/society/ng-interactive/2025/jun/07/jonathan-haidt-anxious-generation-smartphones">‘No smartphones before 14; no social media until 16’: The Anxious Generation author on how to fight back against big tech</a> </p> </aside>  <p>Peltz tells me that parents often feel powerless. “But this is not a blame-the-parents situation. Companies need to make the changes so that these sites are responsible and are safe for children to be on. Parents can’t be expected to keep up with their children when it comes to digital advances. It’s time for these companies to stop blaming parents.”</p> <p>As for teenagers, people can be judgmental, she says. “I think it’s human nature to say, ‘Well my child wouldn’t buy drugs online.’ Or, ‘My child couldn’t be sextorted.’ The answer is that we can all hope that our children won’t do things like that. But children are children. We all know about the frontal cortex, that it doesn’t get fully developed until your 20s. Children make mistakes. They should be allowed to make mistakes and not have to die as a result.”</p> <p>• Can’t Look Away: The Case Against Social Media is in UK cinemas and streaming on <a href="https://www.jolt.film/watch/cantlookaway">jolt.film</a> from 8 August</p> <p><em>• </em>In the UK, the youth suicide charity <a href="https://www.papyrus-uk.org/">Papyrus</a> can be contacted on 0800 068 4141 or email <a href="mailto:pat@papyrus-uk.org">pat@papyrus-uk.org</a>, and in the UK and Ireland <a href="https://www.samaritans.org/">Samaritans</a> can be contacted on freephone 116 123, or email <a href="mailto:jo@samaritans.org">jo@samaritans.org</a> or <a href="mailto:jo@samaritans.ie">jo@samaritans.ie</a>. In the US, the <a href="https://suicidepreventionlifeline.org/">National Suicide Prevention Lifeline</a> is at 988 or chat for support. You can also text HOME to 741741 to connect with a crisis text line counselor. In Australia, the crisis support service <a href="https://www.lifeline.org.au/">Lifeline</a> is 13 11 14. Other international helplines can be found at <a href="http://www.befrienders.org/">befrienders.org</a></p>