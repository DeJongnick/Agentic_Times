<h1>OpenAI launches ‘deep research’ tool that it says can match research analyst</h1>
<div><strong>Date :</strong> 2025-02-03T13:26:07Z &nbsp; | &nbsp; <strong>Auteur :</strong> Dan Milmo Global technology editor &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>OpenAI has stepped up its development of artificial intelligence agents by announcing a new tool that crafts reports which it claims can match the output of a research analyst.</p> <p>The ChatGPT developer said the new tool, “deep research”, “accomplishes in 10 minutes what would take a human many hours”.</p> <p>The announcement comes just a couple of days after the San Francisco-based company said<a href="https://www.theguardian.com/business/2025/jan/31/openai-to-release-new-artificial-intelligence-model-for-free"> it would speed up product releases</a> in response to advances made by OpenAI’s Chinese rival DeepSeek.</p> <p>“Deep research” is an AI agent – the term for a system that can carry out tasks on users’ behalf – and is powered by a version of OpenAI’s latest cutting-edge model, o3.</p> <p>OpenAI said deep research would find, analyse and synthesise hundreds of online sources to create a “comprehensive report”, sifting through “massive amounts” of text, images and PDFs to do so.</p> <p>The company said its tool, which will be available as a button in ChatGPT, is a “significant step” towards its goal of developing artificial general intelligence, a theoretical term referring to systems that match or exceed humans at any intellectual task.</p> <p>Last month, OpenAI unveiled Operator, an AI agent that it claims can book a table at a restaurant or carry out an online shop based on a photo of a shopping list – although is only available in a preview version in the US.</p> <p>In a demo video released on Sunday, OpenAI <a href="https://openai.com/index/introducing-deep-research/">showed deep research</a> analysing the market for translation apps. The company said the tool will take between five and 30 minutes to complete each task and will cite the source for each claim it makes.</p> <p>OpenAI said deep research was for professionals who work in areas such as finance, science and engineering, but it can also examine purchases such as cars and furniture.</p> <p>It is based on o3, OpenAI’s latest “reasoning” model, which takes longer to process queries than conventional models and has yet to be released in full publicly. It comes after OpenAI announced the release on Friday of another derivation of o3 – a free <a href="https://www.theguardian.com/business/2025/jan/31/openai-to-release-new-artificial-intelligence-model-for-free">slimmed-down version</a> called o3-mini.</p> <p>The power of the full o3 model was <a href="https://www.theguardian.com/technology/2025/jan/29/deepseek-artificial-intelligence-ai-safety-risk-yoshua-bengio">flagged in the International AI Safety Report published last week</a>. The study’s lead author, Yoshua Bengio, said its capabilities “could have profound implications for AI risks”. He said o3 had surprised experts, including himself, with its performance in a key abstract reasoning test.</p> <p>Deep research will be available in the US for users of OpenAI’s Pro tier – which costs $200 (£162) a month – but at a limit of up to 100 queries a month, reflecting the cost of processing every query under the tool. It is not available in the UK and Europe.</p> <p>Andrew Rogoyski, a director at the Institute for People-Centred AI at the University of Surrey, said there was a danger that humans could use outputs from tools such as deep research verbatim and not carry out retrospective checks on what they produce.</p> <p>“There’s a fundamental problem with knowledge-intensive AIs and that is it’ll take a human many hours and a lot of work to check whether the machine’s analysis is good,” Rogoyski said.</p>