<h1>UK should act to stop children getting hooked on social media ‘dopamine loops’</h1>
<div><strong>Date :</strong> 2025-07-24T12:20:12Z &nbsp; | &nbsp; <strong>Auteur :</strong> Dan Milmo Global technology editor &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>A leading online safety campaigner has urged the UK government to “detoxify the dopamine loops” of addictive social media platforms as tech companies prepare to implement significant <a href="https://www.theguardian.com/technology/2025/apr/24/ofcom-rules-protect-keep-children-safe-online">child protection measures</a>.</p> <p>Beeban Kidron, a crossbench peer, asked the technology secretary, Peter Kyle, to use the Online Safety Act to bring forward new codes of conduct on disinformation and on tech features that can lead to children becoming addicted to online content.</p> <p>“The secretary of state has a power under the Online Safety Act to bring forward new codes of conduct,” said Kidron. “We have urgently asked him to do so, but so far we have been rebuffed.”</p> <p>Kidron added it was not “nanny state” behaviour to prevent companies that invest billions in making their platforms addictive from targeting under-18s. “It is up to ministers to use their powers to detoxify those dopamine loops – they have the power – so why not to do so right now?”</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/technology/2025/jul/13/fathers-legal-action-smartphone-ban-england-schools">Fathers plan legal action to get smartphones banned in England’s schools</a> </p> </aside>  <p>“Dopamine-like” measures <a href="https://5rightsfoundation.com/wp-content/uploads/2024/08/5rights_DisruptedChildhood_G.pdf">identified by 5Rights</a>, a campaign group founded by Kidron, include displaying the amount of times a user’s post has been liked or shared, mobile phone notifications, and showing content with expiry dates, such as Instagram’s stories feature.</p> <p>Kidron spoke to the Guardian before Friday’s deadline for online platforms – including Facebook, Instagram, TikTok, YouTube, X and Google – to introduce child safety measures, and for <a href="https://www.theguardian.com/society/2025/jun/26/uk-ofcom-study-children-viewing-online-pornography-age-checks">pornography sites to bring in stringent age checking</a>.</p> <p>Responding to Kidron’s comments, a Department for Science, Innovation and Technology spokesperson said the new laws were a “foundation for a safer online world” but “we will not hesitate to go further if needed”.</p> <p>Kyle said the child safety measures represented a “line in the sand” that would “reclaim the digital space for young people”.</p> <p>Age-checking measures could also be required for social media sites that allow harmful content, such as <a href="https://www.childrenscommissioner.gov.uk/resource/a-lot-of-it-is-actually-just-abuse-young-people-and-pornography/">X, the platform where young people were most likely to have seen pornography</a>, according to research published by the children’s commissioner for England, Dame Rachel de Souza.</p> <p>X announced on Thursday that if it was unable to determine whether a user was 18 or over, they would be defaulted into sensitive content settings and would not be able to view adult material. It added that it would introduce facial age estimation, where a user’s age is gauged via a selfie, or require the submission of government-issued ID, such as a passport, before users could view adult content.</p> <p>Dame Melanie Dawes, Ofcom’s chief executive, said: “Prioritising clicks and engagement over children’s online safety will no longer be tolerated in the UK. Our message to tech firms is clear: comply with age checks and other protection measures set out in our codes, or face the consequences of enforcement action from Ofcom.”</p> <p>The changes mean that social media companies must, as a priority, prevent children from seeing pornography as well as harmful content that encourages suicide, self-harm or eating disorders. They must also suppress the spread of harmful content, such as violent, hateful or abusive material and online bullying.</p> <p>Companies that breach the act face fines of up to 10% of global turnover, which, in the case of Instagram’s parent company, Meta, would amount to $16.5bn. In extreme cases, sites or apps could be blocked in the UK. Tech executives could also be prosecuted if they ignored Ofcom demands to comply with child safety duties.</p> <p>Ofcom has outlined a series of measures that comply with the child safety requirements. Those include: sites and apps having procedures for taking down dangerous content quickly; children having a “straightforward” way to report harmful content; and algorithms, which recommend content to users, being able to filter out harmful material.</p> <p>The watchdog also announced it is launching an “extensive” monitoring programme for platforms popular with children including Facebook, Instagram, Roblox, Snap, TikTok and YouTube.</p> <p>Other <a href="https://help.x.com/en/rules-and-policies/age-assurance">age-checking measures</a> announced by X included checking if a user had previously indicated that they were under 18 or if an account was created in 2012 or earlier. Bluesky, Discord, Grindr and Reddit have also committed to age-gating measures. Ofcom will assess whether these approaches comply with the act.</p> <p>Meta, which also owns Facebook, has said it has a multilayered approach in place that complies with age-checking requirements, including its teenage account feature – a default setting for users under 18 – that it says already provides an “age appropriate” experience for young users. TikTok, which argues it already blocks the vast majority of content prohibited to children, said it was introducing new age-checking measures for certain restricted material from Friday.</p> <p>Pornography sites, such as Pornhub, have committed to introducing age checks from Friday. Measures recommended by Ofcom include: facial age estimation, where technology assesses a person’s likely age through a live photo or video; checking a person’s age via their credit card provider, bank or mobile phone network operator; photo ID matching, where a passport or similar ID is checked against a selfie; or a “digital identity wallet” that contains proof of age.</p>