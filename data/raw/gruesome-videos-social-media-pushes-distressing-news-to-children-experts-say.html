<h1>‘Gruesome videos’: social media pushes distressing news to children, experts say</h1>
<div><strong>Date :</strong> 2025-10-16T09:11:18Z &nbsp; | &nbsp; <strong>Auteur :</strong> Robert Booth Technology editor &nbsp; | &nbsp; <strong>Journal :</strong> Society</div>
<p>More than half of children who get news from social media are left worried and upset after seeing content that involves war, violence and death, according to new research that found social media companies are “pushing” distressing news to children who are not seeking it.</p> <p>Videos of the murder of Charlie Kirk, the Liverpool parade car-ramming attack, scenes from wars, shootings, stabbings and car crashes have recently been pushed into children’s feeds, research by Internet Matters, an online safety organisation, has found. As a result, 39% of those who saw <a href="https://www.theguardian.com/society/2025/jan/24/talking-about-extreme-online-violence-with-young-people-advice-for-parents">distressing content</a> described themselves as very or extremely upset and worried by it.</p> <p>More than two-thirds of children are getting news from social media apps including TikTok and Instagram, but 40% do not follow news-focused accounts and are instead coming across stories through recommendation algorithms. Nearly two-thirds (61%) of those who get news from social media have seen a worrying or upsetting story in the past month.</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/australia-news/2025/oct/14/instagram-teenagers-australia-under-16s-social-media-ban">Instagram restricts what teenagers can see weeks before Australia’s under-16s social media ban begins</a> </p> </aside>  <p>One 14-year-old girl told researchers: “On TikTok you can see stabbings and kidnappings, which are just not nice to see, especially when you are a bit younger, it makes you feel uncomfortable.”</p> <p>Another girl, 17, said: “On Instagram, before videos get taken down, I think there’s quite a lot of stabbing videos or gruesome videos like that. When Liam Payne died [the One Direction star fell from a hotel balcony] there was video of him circulating and I thought it wasn’t very nice. I would have wanted a trigger warning.”</p> <p>Of news that pops up in his feed, a 13-year-old boy said: “You don’t want to see it sometimes and don’t want to think about it.”</p> <p>The survey findings reflect a wider trend in social media use: the proportion of time users spend viewing content posted by their friends is falling on several platforms. Meta said in <a href="https://www.slideshare.net/slideshow/meta-s-opening-statement-ftc-v-meta-platforms-inc/277951345">court filings</a> this April that only 8% of an Instagram user’s time is now spent viewing friend posts, down by over a third since 2023, with algorithmically recommended posts instead increasingly dominating users’ feeds, contributing to the supposed phenomenon of “brain rot”.</p>    <p>The vast majority of children (86%) do not know how to reset the explore algorithm on their social accounts, which serves the upsetting material, according to the research which involved a survey and focus groups with more than 1,000 11- to 17-year-olds.</p> <p>“The shift away from established news channels is radically changing how children and young people consume news, and it is having worrying consequences,” said Rachel Huggins, co-chief executive of Internet Matters, which provides advice to parents and is part-supported by tech companies including TikTok.</p> <p>“The algorithmic design of social media platforms is enabling children to see negative and upsetting content [and it is delivering it] to millions of children and young people who are not seeking it out.”</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/technology/2025/oct/14/instagram-parental-guidance-pg-13-age-rating-system-meta">Instagram to bring in version of PG-13 system to protect children, says Meta</a> </p> </aside>  <p>Chi Onwurah MP, the Labour chair of the Commons science and technology committee, said the findings reinforced its conclusion that the Online Safety Act “isn’t up to scratch to protect users”. She called for a stronger regime “that discourages the viral spread of misinformation, regulates generative AI and places much-needed standards on to social media companies”.</p> <p>Under the Online Safety Act, codes to protect children <a href="https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer#how-the-act-tackles-misinformation-and-disinformation">require</a> social media companies to give children age-appropriate access to content that depicts or encourages serious violence or injury. Younger children are seeing news relating to war and conflict, and violence and crime, less than older children but Internet Matters said: “It is still concerning that 11- to 12-year-olds are seeing this content at all given many social media platforms have a minimum age of 13+ outlined in their terms of service.”</p> <p>According to TikTok, human blood and extreme physical fighting cannot be included in its “for you” feed and the platform does not allow gory, gruesome, disturbing or extremely violent content. It said it uses independent factcheckers and allows parents to block their teens from using the app during times they control and to filter content.</p> <p>Instagram has been approached for comment. A UK government spokesperson said new child safety requirements under the Online Safety Act meant it expected young people to be protected from harmful content, including violent material, and illegal mis- and disinformation, and this should result in “less toxic feeds”.</p> <p>“We will not hesitate to act where evidence shows further intervention is needed to protect children,” they said. </p>