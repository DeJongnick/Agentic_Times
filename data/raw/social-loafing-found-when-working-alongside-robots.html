<h1>‘Social loafing’ found when working alongside robots</h1>
<div><strong>Date :</strong> 2023-10-18T04:00:32Z &nbsp; | &nbsp; <strong>Auteur :</strong> Kevin Rawlinson &nbsp; | &nbsp; <strong>Journal :</strong> Science</div>
<p>People tend to pay less attention to tasks when working alongside a robot, according to research that found evidence of “social loafing” – where team members work less hard if they think others will cover for them.</p> <p>Researchers at the Technical University of Berlin said people come to see robots as part of their team. Where they think a colleague – or the technology – performs particularly well, or where they think their own contribution would not be appreciated, people tend to take a more laid-back approach, the scientists suggested.</p> <p>“Teamwork is a mixed blessing,” said Dietlind Helene Cymek, the first author of the study, which appears in the journal Frontiers in Robotics and AI.</p> <p>“Working together can motivate people to perform well but it can also lead to a loss of motivation because the individual contribution is not as visible. We were interested in whether we could also find such motivational effects when the team partner is a robot.”</p> <p>The team tested their hypothesis by asking a cohort of workers to check the quality of a series of tasks; half of whom were told the tasks had been performed by a robot. While they did not work directly with the robot, named Panda, those people had seen it and were able to hear it operating.</p> <p>The workers were all asked to carry out checks for errors on circuit boards. Their activity was monitored by the researchers, who blurred out the images of the boards the workers received, only showing them an image they could check once they actively opened it.</p> <p>Initially, they said they found no statistical difference in the time the two groups – those who were told they were working with a robot and those who were not – spent inspecting the circuit boards, or in the area they searched for errors.</p> <p>However, when the researchers investigated the participants’ error rates, they found those working with Panda were catching fewer defects after they had seen the robot had successfully flagged many errors. They said this could reflect a “looking but not seeing” effect, where people engage less once they feel a colleague or resource is reliable.</p> <p>While participants – who were asked to rate their own performance – thought they were paying an equivalent amount of attention, the researchers felt that subconsciously they had begun to assume Panda had picked up defects well.</p> <p>“It is easy to track where a person is looking, but much harder to tell whether that visual information is being sufficiently processed at a mental level,” said Dr Linda Onnasch, a senior author of the study.</p>