<h1>Mark Zuckerberg’s end to Meta factchecking is a desperate play for engagement</h1>
<div><strong>Date :</strong> 2025-01-10T19:39:22Z &nbsp; | &nbsp; <strong>Auteur :</strong> William Antonelli &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p><a href="https://www.theguardian.com/technology/mark-zuckerberg">Mark Zuckerberg</a> craves one metric more than any other: engagement, the statistic that tracks how long social media users spend scrolling, clicking, commenting, and viewing ads. More engagement, more profit. The <a href="https://www.theguardian.com/technology/meta">Meta</a> CEO will do almost anything to keep users online for an extra two minutes – even, it seems, surrender his websites to a flood of fake news.</p> <p>On Tuesday, Zuckerberg announced that his company plans to <a href="https://www.theguardian.com/technology/2025/jan/07/meta-facebook-instagram-threads-mark-zuckerberg-remove-fact-checkers-recommend-political-content">fire its US factcheckers</a> and weaken its ability to moderate disinformation on Facebook, Instagram and Threads. This new policy is meant to <a href="https://www.theguardian.com/commentisfree/2025/jan/08/mark-zuckerberg-supporting-trump-maga">curry favor with the coming Trump administration</a>. It’s also a desperate attempt to boost engagement across all Meta’s social networks.</p> <p>Studies show that false social media posts <a href="https://www.theguardian.com/technology/2018/mar/08/scientists-truth-fiction-twitter-bots">spread up to 20 times faster</a> than true ones, especially if the posts feature radical, outrageous content, such as government conspiracy theories, racist grievances and calls to violence. That’s 2000% times more engagement, and 2000% times the ad revenue. And the more “novel” a post is – oftentimes, the more detached from reality – the better.</p> <p>As factchecking attempts end, it’s a guarantee that Meta’s platforms, <a href="https://www.theguardian.com/technology/article/2024/sep/05/racism-misogyny-lies-how-did-x-become-so-full-of-hatred-and-is-it-ethical-to-keep-using-it">much like X before them</a>, will become a wasteland of fake news and misinformation. Zuckerberg said explicitly that he was following <a href="https://www.theguardian.com/technology/elon-musk">Elon Musk</a>’s example.</p> <p>We can already see this happening. <a href="https://www.theguardian.com/us-news/2025/jan/10/rightwing-misinformation-los-angeles-fire">Misinformation</a> about the <a href="https://www.theguardian.com/us-news/california-wildfires">wildfires</a> ravaging Los Angeles is spreading as fast as the blazes themselves. Meta fired its factchecking team because slapping a disclaimer on a post discourages people from interacting with it, and that’s exactly the opposite of what Zuckerberg wants.</p> <p>“Absent the moderating force of factchecking, we’ll see more content that’s hyper-partisan, vitriolic, and hostile,” said Dr Cody Buntain, an assistant professor at the University of Maryland who studies social media disinformation. “The people that are already potentially more extreme, they’ll be more engaged in the platform. There’ll be more content that caters to their interests.”</p> <p>Extreme and misleading content is designed to inflame emotions. There would be no point to posting it otherwise. It’s meant to make you angry, to bypass the logical parts of your brain and force you to react, either positively or negatively. Yet, whether that reaction involves liking the post, sharing it or even leaving a comment to correct the record, the result is the same: you’ve engaged, dropping a few more cents into Meta’s coffers. Meta’s algorithm does not register the conscientious objection of your “angry face” reaction, only the fact that you reacted, which boosts the original post.</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/us-news/2025/jan/10/meta-ending-dei-program">Meta terminates its DEI programs days before Trump inauguration</a> </p> </aside>  <p>Meta has always believed that juicing engagement is worth any cost. In 2016, Meta vice-president Andrew Bosworth <a href="https://www.theguardian.com/technology/2018/mar/29/facebook-memo-mission-andrew-bosworth">argued in an email</a> that inciting suicides and terrorist attacks was an acceptable price to pay for the “de facto” benefits of connecting users. When the email leaked in 2018, Zuckerberg said he disagreed – but it’s clearly still the prevailing philosophy at Meta. Bosworth was promoted to chief technology officer in 2022.</p> <p>For the same reason, Meta continues to aggressively market its products towards children and teens, despite years of criticism. We know that excessive social media use can <a href="https://www.yalemedicine.org/news/social-media-teen-mental-health-a-parents-guide">lead to anxiety and depression in teens</a>. But as Facebook’s user base grows older, Meta knows that its survival depends on children, who are <a href="https://www.pewresearch.org/internet/fact-sheet/mobile/">dependent on their phones</a> more than any other age group, polling shows.</p> <p>Whether a user is 12 or 62, ad revenue is ad revenue. And whether you’re sharing fake news to praise it, laugh at it or rage at it, engagement is engagement.</p> <p>Two years ago, the end of factchecking might have forced Zuckerberg to endure another another congressional hearing. But with the second reign of <a href="https://www.theguardian.com/us-news/donaldtrump">Donald Trump</a> looming, Meta finally has permission to abandon its ethics and chase the dragon of engagement wherever it leads – even if it leads to the death of truth on the internet.</p>