<h1>YouTube removes advertising from account accused of homophobic abuse</h1>
<div><strong>Date :</strong> 2019-06-05T20:27:09Z &nbsp; | &nbsp; <strong>Auteur :</strong> Alex Hern and Kari Paul &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>YouTube has removed advertising from material by a user who subjected a journalist to repeated homophobic abuse in videos, after the platform faced criticism over its failure to act.</p> <p>Carlos Maza, a video journalist for the US news site Vox, went public last week with a complaint that the rightwing YouTube personality Steven Crowder was engaged in a long-term homophobic harassment campaign. In a <a href="https://twitter.com/gaywonk/status/1134264395717103617">compilation video Maza created</a> of some of his mentions on Crowder’s show, the host attacks Maza as a “gay Mexican”, a “lispy queer” and a “token Vox gay atheist sprite”.</p> <p>YouTube initially argued that Crowder’s “criticism” was debating rather than harassment, saying in a public statement on Tuesday: “Our teams spent the last few days conducting an in-depth review of the videos flagged to us, and while we found language that was clearly hurtful, the videos as posted don’t violate our policies.” It changed its decision on Wednesday, saying that upon review it found Crowder’s channel “has harmed the broader community and is against our YouTube Partner Program policies” and that it would be demonetised, meaning advertisers would be removed from the channel.</p> <p>“In the past, we felt our responses to some of these situations were slow and didn’t always address our broader community’s concerns,” YouTube said in a blogpost. “Our ultimate goal here is to streamline our response so we can make better, faster decisions and communicate them clearly.”</p> <p>The company initially said Crowder’s videos did not breach its <a href="https://support.google.com/youtube/answer/2802268?hl=en&amp;ref_topic=2803176">harassment and cyberbullying policy</a>, which explicitly bars “content that makes hurtful and negative personal comments/videos about another person”, or its hate speech policy, which bars creators from using “stereotypes that incite or promote hatred” based on attributes including ethnicity and sexual orientation.</p> <p>“This has been going on for years, and I’ve tried to flag this shit on several occasions,” Maza said when he posted the initial<strong> </strong>video about harassment. “But YouTube is never going to actually enforce its policies. Because Crowder has 3 million YouTube subscribers, and enforcing their rules would get them accused of anti-conservative bias.” </p> <p>Responding on Wednesday morning to YouTube’s decision, Maza said: “It’s going to get so much worse now. YouTube has publicly stated that racist and homophobic abuse doesn’t violate their anti-bullying policies. Crowder and his allies are going to be emboldened. I genuinely can’t imagine what LGBT employees at YouTube are doing right now.</p> <p>“You can harass queer people as much as you want as long as it’s sandwiched between ‘debating’.”</p> <p>He also appeared to be unsatisfied with YouTube’s decision to demonetise Crowder’s videos, saying:<strong> “</strong>Crowder’s revenue stream isn’t from YouTube ads. It’s from selling merch and ‘Socialism Is For Fags’ shirts to millions of loyal customers, that @YouTube continues to drive to his channel. For free.”</p> <p>YouTube’s response has<strong> </strong>sparked a wave of criticism, with many noting that it came five days into Pride month. The main YouTube accounts on <a href="https://twitter.com/youtube">Twitter</a> and <a href="https://www.youtube.com/user/YouTube">YouTube</a> are decked with rainbow flags to celebrate the LGBTQ+ community.</p> <p>The company is still addressing its last crisis, after <a href="https://www.nytimes.com/2019/06/03/world/americas/youtube-pedophiles.html">a New York Times report</a> found that a paedophile ring that YouTube <a href="https://www.theguardian.com/society/2019/feb/28/youtube-turns-off-comments-on-videos-of-children-amid-child-safety-fears">attempted to shut down in February</a> was not only still operating, but also being aided by the company’s own algorithm.</p> <p>Videos of children in swimwear and underwear were being linked together by the video-sharing site’s recommendation algorithm, creating an automatic watchlist for paedophiles who trawl the site for “borderline” content that sexualises children without breaking child exploitation laws.</p> <p>The company refused to remove recommendations from videos of children, arguing that doing so would hurt creators who rely on the recommendations to drive an audience to their videos. It did, however, introduce a rule requiring any minor livestreaming on the site to be accompanied by an adult.</p> <p>In February, YouTube said: “Any content – including comments – that endangers minors is abhorrent and we have clear policies prohibiting this on YouTube.<em><br><br></em>“We took immediate action by deleting accounts and channels, reporting illegal activity to authorities, and disabling comments on tens of millions of videos that include minors. There’s more to be done, and we continue to work to improve and catch abuse more quickly.”</p>