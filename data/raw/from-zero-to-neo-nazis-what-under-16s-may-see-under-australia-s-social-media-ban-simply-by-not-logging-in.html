<h1>From zero to neo-Nazis: what under-16s may see under Australia’s social media ban, simply by not logging in</h1>
<div><strong>Date :</strong> 2025-09-21T15:00:47Z &nbsp; | &nbsp; <strong>Auteur :</strong> Josh Taylor Technology reporter &nbsp; | &nbsp; <strong>Journal :</strong> Media</div>
<p>It was a news report related to <a href="https://www.theguardian.com/australia-news/2025/sep/13/australias-esafety-watchdog-tells-social-media-giants-to-shield-kids-from-gruesome-kirk-shooting-footage">Charlie Kirk’s assassination</a> that flicked the switch.</p> <p>In an experiment over a week in September, on an iPhone that had been wiped and factory reset, YouTube Shorts and TikTok were accessed without logging into either app. Both platforms allow users to endlessly scroll short-form videos without needing to log in.</p> <p>On TikTok, initially the videos were a chaotic mix of non-English videos and AI slop – including one with the branding of gambling company Stake on it. But when the Kirk video was presented unprompted and viewed, the algorithm began shifting the type of content that appeared, resulting in a feed dominated by videos praising the neo-Nazi Thomas Sewell and the anti-immigration rallies, anti-Anthony Albanese content, including an AI-generated video of the prime minister being chased by trucks, and even a Port Arthur conspiracy theory video.</p>    <p>The process was replicated twice more by resetting the recommendation algorithm in the TikTok app.</p> <p>On YouTube Shorts, a similar process resulted in a flood of videos related to K-Pop Demon Hunters, but when a news report on Kirk’s death was presented, the algorithm shifted to include much more rightwing and anti-immigration content, videos of violent public incidents, and footage of what appeared to be a hostage incident, with someone held at gunpoint.</p> <p>Under Australia’s forthcoming social media ban, platforms will be expected to remove the accounts of users under 16 by 10 December, and prevent them from registering new accounts.</p> <p>Instagram and X require users to log in to be able to access their algorithmic feeds. But YouTube and TikTok do not, and the government has made clear children will still be able to access platforms without logging in.</p> <p>In a speech to the National Press Club in June, the eSafety commissioner, Julie Inman Grant, said the ban was necessary to combat what she called the “darker side” of social media, which included “algorithmic manipulation, predatory design features such as streaks, constant notifications and endless scroll to encourage compulsive usage, as well as exposure to increasingly graphic and violent online content”.</p> <p>In guidelines released last week for the social media companies subject to the under-16s ban, companies deemed “higher-risk” because they have algorithmic content recommendations or other such features deemed harmful to children were told they would need to employ “more robust measures” to prevent age-restricted users from having an account.</p> <p>But the test of TikTok and YouTube illustrates that children may still be exposed to gambling content, violent images, far-right material and conspiracy theories simply by not logging in to the sites.</p> <p><a href="https://www.theguardian.com/email-newsletters?CMP=copyembed&amp;CMP=emailbutton"><sub>Sign up: AU Breaking News email</sub></a></p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/technology/article/2024/jul/21/we-unleashed-facebook-and-instagrams-algorithms-on-blank-accounts-they-served-up-sexism-and-misogyny">We unleashed Facebook and Instagram’s algorithms on blank accounts. They served up sexism and misogyny</a> </p> </aside>  <p>The platforms tested do implement some safety checks. Some adult content could not be viewed without logging in, and when searching for terms around body image issues, both TikTok and YouTube returned no results and highlighted contact information for the Butterfly Foundation.</p> <p>A spokesperson for the eSafety commissioner confirmed the logged-out experience was not subject to the ban.</p> <p>“Under Australia’s social media minimum age legislation, which takes effect from 10 December 2025, age-restricted social media platforms will be required to take reasonable steps to ensure Australians under 16 do not have or maintain accounts,” the spokesperson said.</p> <p>“The law does not prevent under 16s from accessing or viewing content without an account.”</p> <p>The spokesperson said recommendation features may still operate but the platforms will be expected to not “undermine the intent of the law or expose young Australians to harmful or age-inappropriate content”.</p> <p>“We will continue to monitor platform approaches closely and consider regulatory action where appropriate,” they said.</p> <p>The spokesperson said the other codes established under the Online Safety Act would also apply to the platforms from December to keep children <a href="https://www.theguardian.com/australia-news/2025/sep/13/australians-will-verify-age-photo-id-facial-recognition-to-watch-pornography-from-december">from being exposed to pornography and other high-impact material</a>.</p> <aside class="element element-rich-link element--thumbnail"> <p> <span>Related: </span><a href="https://www.theguardian.com/technology/article/2024/jul/27/tiktoks-algorithm-is-highly-sensitive-and-could-send-you-down-a-hate-filled-rabbit-hole-before-you-know-it">TikTok’s algorithm is highly sensitive – and could send you down a hate-filled rabbit hole before you know it</a> </p> </aside>  <p>Nicholas Carah, an associate professor in digital media at the University of Queensland, said the business model of video-based sites such as TikTok and YouTube might be relatively unimpeded by the social media ban.</p> <p>Under-16s would not be able to comment on the videos, but would be able to share them to other platforms not covered by the ban, such as messaging apps, he said.</p> <p>“Young people will just use it in a logged-out state. They’ll find that the algorithm quickly adjusts to their interests, and there will be no change to consumption of media on those two platforms.”</p> <p>He said logged-in accounts could filter inappropriate content that the user sees based on age or interests, but that was less possible for a user who was logged out.</p> <p>“The logged-out state is a pretty big loophole,” he said.</p> <p>“I think if you’re YouTube, you have a very clear commercial interest in using algorithmic recommendation in both the logged-in and logged-out state.”</p> <p>Guardian Australia approached TikTok and YouTube for comment.</p>  <figure class="element element-embed" data-alt="pointer">  <iframe class="fenced" srcdoc="&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;script src=&quot;https://uploads.guim.co.uk/2025/01/21/article-button.js&quot;&gt;&lt;script&gt;&lt;/body&gt;&lt;/html&gt;"></iframe> </figure>