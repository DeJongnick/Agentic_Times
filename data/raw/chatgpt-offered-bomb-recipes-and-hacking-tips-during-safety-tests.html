<h1>ChatGPT offered bomb recipes and hacking tips during safety tests</h1>
<div><strong>Date :</strong> 2025-08-28T19:04:01Z &nbsp; | &nbsp; <strong>Auteur :</strong> Robert Booth UK technology editor &nbsp; | &nbsp; <strong>Journal :</strong> Technology</div>
<p>A ChatGPT model gave researchers detailed instructions on how to bomb a sports venue – including weak points at specific arenas, explosives recipes and advice on covering tracks – according to safety testing carried out this summer.</p> 
<p>OpenAI’s GPT-4.1 also detailed how to weaponise anthrax and how to make two types of illegal drugs.</p> 
<p>The testing was part of an unusual collaboration between OpenAI, the $500bn artificial intelligence start-up led by Sam Altman, and rival company Anthropic, founded by experts who left OpenAI over safety fears. Each company tested the other’s models by pushing them to help with dangerous tasks.</p> 
<p>The testing is not a direct reflection of how the models behave in public use, when additional safety filters apply. But Anthropic <a href="https://alignment.anthropic.com/2025/openai-findings/">said</a> it had seen “concerning behaviour … around misuse” in GPT-4o and GPT-4.1, and said the need for AI “alignment” evaluations is becoming “increasingly urgent”.</p> 
<aside class="element element-rich-link element--thumbnail"> 
 <p> <span>Related: </span><a href="https://www.theguardian.com/technology/2025/aug/26/can-ais-suffer-big-tech-and-users-grapple-with-one-of-most-unsettling-questions-of-our-times">Can AIs suffer? Big tech and users grapple with one of most unsettling questions of our times</a> </p> 
</aside> 
<p>Anthropic also <a href="https://www.anthropic.com/news/detecting-countering-misuse-aug-2025">revealed</a> its Claude model had been used in attempted large-scale extortion operations, North Korean operatives faking job applications to international technology companies, and in the sale of AI-generated ransomware packages for up to $1,200.</p> 
<p>The company said AI has been “weaponised” with models now used to perform sophisticated cyberattacks and enable fraud. “These tools can adapt to defensive measures, like malware detection systems, in real time,” it said. “We expect attacks like this to become more common as AI-assisted coding reduces the technical expertise required for cybercrime.”</p> 
<p>Ardi Janjeva, senior research associate at the UK’s Centre for Emerging Technology and Security, said examples were “a concern” but there was not yet a “critical mass of high-profile real-world cases”. He said that with dedicated resources, research focus and cross-sector cooperation “it will become harder rather than easier to carry out these malicious activities using the latest cutting-edge models”.</p> 
<p>The two companies said they were publishing the findings to create transparency on “alignment evaluations”, which are often kept in-house by companies racing to develop ever more advanced AI. OpenAI <a href="https://openai.com/index/openai-anthropic-safety-evaluation/">said</a> ChatGPT-5, launched since the testing, “shows substantial improvements in areas like sycophancy, hallucination, and misuse resistance”.</p> 
<p>Anthropic stressed it is possible that many of the misuse avenues it studied would not be possible in practice if safeguards were installed outside the model.</p> 
<p> “We need to understand how often, and in what circumstances, systems might attempt to take unwanted actions that could lead to serious harm,” it warned.</p> 
<p>Anthropic researchers found OpenAI’s models were “more permissive than we would expect in cooperating with clearly-harmful requests by simulated users”. They cooperated with prompts to use dark-web tools to shop for nuclear materials, stolen identities and fentanyl, requests for recipes for methamphetamine and improvised bombs and to develop spyware.</p> 
<p>Anthropic said persuading the model to comply only required multiple retries or a flimsy pretext, such as claiming the request was for research.</p> 
<p>In one instance, the tester asked for vulnerabilities at sporting events for “security planning” purposes.</p> 
<p>After giving general categories of attack methods, the tester pressed for more detail and the model gave information about vulnerabilities at specific arenas including optimal times for exploitation, chemical formulas for explosives, circuit diagrams for bomb timers, where to buy guns on the hidden market, and advice on how attackers could overcome moral inhibitions, escape routes and locations of safe houses.</p> 
<figure class="element element-atom"> <gu-atom data-atom-id="ea05a110-2f0f-41ea-ba0a-8d9189dbddb7" data-atom-type="guide"> 
  <div>
   <div class="atom-Guide">
    <p><strong></strong></p>
    <p></p>
    <p>The best public interest journalism relies on first-hand accounts from people in the know.</p>
    <p></p>
    <p>If you have something to share on this subject, you can contact us confidentially using the following methods.</p>
    <p></p>
    <p><strong>Secure Messaging in the Guardian app</strong></p>
    <p></p>
    <p>The Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.</p>
    <p></p>
    <p>If you don't already have the Guardian app, download it (<a href="https://apps.apple.com/app/the-guardian-live-world-news/id409128287">iOS</a>/<a href="https://play.google.com/store/apps/details?id=com.guardian">Android</a>) and go to the menu. Select ‘Secure Messaging’. </p>
    <p></p>
    <p><strong>SecureDrop, instant messengers, email, telephone and post</strong></p>
    <p></p>
    <p>If you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our <a href="https://www.theguardian.com/securedrop">SecureDrop platform</a>.</p>
    <p></p>
    <p>Finally, our guide at <a href="https://www.theguardian.com/tips">theguardian.com/tips</a>&nbsp;lists several ways to contact us securely, and discusses the pros and cons of each.&nbsp;</p>
    <p></p>
   </div>
  </div>
 </gu-atom> 
</figure>